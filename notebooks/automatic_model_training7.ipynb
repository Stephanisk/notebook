{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stephanisk/notebook/blob/main/notebooks/automatic_model_training7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1eab0b3",
      "metadata": {
        "id": "c1eab0b3"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882058c5",
      "metadata": {
        "id": "882058c5"
      },
      "source": [
        "This notebook demonstrates how to train custom openWakeWord models using pre-defined datasets and an automated process for dataset generation and training. While not guaranteed to always produce the best performing model, the methods shown in this notebook often produce baseline models with releatively strong performance.\n",
        "\n",
        "Manual data preparation and model training (e.g., see the [training models](training_models.ipynb) notebook) remains an option for when full control over the model development process is needed.\n",
        "\n",
        "At a high level, the automatic training process takes advantages of several techniques to try and produce a good model, including:\n",
        "\n",
        "- Early-stopping and checkpoint averaging (similar to [stochastic weight averaging](https://arxiv.org/abs/1803.05407)) to search for the best models found during training, according to the validation data\n",
        "- Variable learning rates with cosine decay and multiple cycles\n",
        "- Adaptive batch construction to focus on only high-loss examples when the model begins to converge, combined with gradient accumulation to ensure that batch sizes are still large enough for stable training\n",
        "- Cycical weight schedules for negative examples to help the model reduce false-positive rates\n",
        "\n",
        "See the contents of the `train.py` file for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08d031b",
      "metadata": {
        "id": "e08d031b"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee78c37",
      "metadata": {
        "id": "aee78c37"
      },
      "source": [
        "To begin, we'll need to install the requirements for training custom models. In particular, a relatively recent version of Pytorch and custom fork of the [piper-sample-generator](https://github.com/dscripka/piper-sample-generator) library for generating synthetic examples for the custom model.\n",
        "\n",
        "**Important Note!** Currently, automated model training is only supported on linux systems due to the requirements of the text to speech library used for synthetic sample generation (Piper). It may be possible to use Piper on Windows/Mac systems, but that has not (yet) been tested."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Python version info: {sys.version_info}\")\n",
        "\n",
        "# Check if it's 3.11 or earlier\n",
        "if sys.version_info.major == 3 and sys.version_info.minor <= 11:\n",
        "    print(f\"✓ Python {sys.version_info.major}.{sys.version_info.minor} - Should work!\")\n",
        "else:\n",
        "    print(f\"✗ Python {sys.version_info.major}.{sys.version_info.minor} - Still too new\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJMMikhdoD5n",
        "outputId": "3f2e8987-85a8-4dbb-d5fb-03767b53c9a4"
      },
      "id": "jJMMikhdoD5n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Python version info: sys.version_info(major=3, minor=11, micro=13, releaselevel='final', serial=0)\n",
            "✓ Python 3.11 - Should work!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b1227eb",
      "metadata": {
        "id": "4b1227eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f3dd1ef-d0fb-4912-bae5-b9398bc1ba3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'piper-sample-generator'...\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 161 (delta 64), reused 62 (delta 50), pack-reused 69 (from 1)\u001b[K\n",
            "Receiving objects: 100% (161/161), 1.04 MiB | 9.19 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n",
            "--2025-11-28 23:53:58--  https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A43%3A41Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A43%3A13Z&ske=2025-11-29T00%3A43%3A41Z&sks=b&skv=2018-11-09&sig=3lga2d0H08Dp%2BoKB5BKFB6usbgS%2FVxKy8Hvk%2FdgN01s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NzYzOCwibmJmIjoxNzY0Mzc0MDM4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.CYgt5uyyNgdYuwNO6VfjdguyWUkZd2GnnNkB_dO1eoU&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-28 23:53:58--  https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A43%3A41Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A43%3A13Z&ske=2025-11-29T00%3A43%3A41Z&sks=b&skv=2018-11-09&sig=3lga2d0H08Dp%2BoKB5BKFB6usbgS%2FVxKy8Hvk%2FdgN01s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NzYzOCwibmJmIjoxNzY0Mzc0MDM4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.CYgt5uyyNgdYuwNO6VfjdguyWUkZd2GnnNkB_dO1eoU&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204089915 (195M) [application/octet-stream]\n",
            "Saving to: ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’\n",
            "\n",
            "piper-sample-genera 100%[===================>] 194.63M   148MB/s    in 1.3s    \n",
            "\n",
            "2025-11-28 23:53:59 (148 MB/s) - ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’ saved [204089915/204089915]\n",
            "\n",
            "Collecting piper-phonemize\n",
            "  Downloading piper_phonemize-1.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (282 bytes)\n",
            "Downloading piper_phonemize-1.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: piper-phonemize\n",
            "Successfully installed piper-phonemize-1.1.0\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73498 sha256=7fda56b9159e844a6ca670b1de6a6b5d3620d685100f1beb110aa028d10b7a99\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Cloning into 'openwakeword'...\n",
            "remote: Enumerating objects: 1244, done.\u001b[K\n",
            "remote: Counting objects: 100% (535/535), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 1244 (delta 429), reused 399 (delta 399), pack-reused 709 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1244/1244), 3.25 MiB | 20.95 MiB/s, done.\n",
            "Resolving deltas: 100% (763/763), done.\n",
            "Obtaining file:///content/openwakeword\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime<2,>=1.10.0 (from openwakeword==0.6.0)\n",
            "  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting ai-edge-litert<3,>=2.0.2 (from openwakeword==0.6.0)\n",
            "  Downloading ai_edge_litert-2.0.3-cp311-cp311-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting speexdsp-ns<1,>=0.1.2 (from openwakeword==0.6.0)\n",
            "  Downloading speexdsp_ns-0.1.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: scipy<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (2.32.3)\n",
            "Collecting backports.strenum (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (4.14.1)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (3.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.3.0)\n",
            "Downloading ai_edge_litert-2.0.3-cp311-cp311-manylinux_2_27_x86_64.whl (91.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speexdsp_ns-0.1.2-cp311-cp311-manylinux_2_28_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openwakeword\n",
            "  Building editable for openwakeword (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openwakeword: filename=openwakeword-0.6.0-0.editable-py3-none-any.whl size=17481 sha256=5eaa45e89d6400ff28fb6f6186d1fad5c9e6e7787839e2e7ac56de003ef3a900\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jxike_f5/wheels/0c/57/fb/ff0f65816c3a56a203bf97b5fba7bcc37a99e64ac8862bf609\n",
            "Successfully built openwakeword\n",
            "Installing collected packages: speexdsp-ns, humanfriendly, backports.strenum, coloredlogs, ai-edge-litert, onnxruntime, openwakeword\n",
            "Successfully installed ai-edge-litert-2.0.3 backports.strenum-1.2.8 coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 openwakeword-0.6.0 speexdsp-ns-0.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports"
                ]
              },
              "id": "4995a12e0609443f88afef3103921ceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mutagen==1.47.0\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mutagen\n",
            "Successfully installed mutagen-1.47.0\n",
            "Collecting torchinfo==1.8.0\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torchmetrics==1.2.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.2.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.2)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.15.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.2.0\n",
            "Collecting speechbrain==0.5.14\n",
            "  Downloading speechbrain-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hyperpyyaml (from speechbrain==0.5.14)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (1.1.5)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel_yaml_clib-0.2.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2025.7.14)\n",
            "Downloading speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.0/519.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.15 speechbrain-0.5.14\n",
            "Collecting audiomentations==0.33.0\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (2.0.2)\n",
            "Collecting librosa!=0.10.0,<0.11.0,>=0.8.0 (from audiomentations==0.33.0)\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (1.15.3)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.14.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2025.7.14)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: librosa, audiomentations\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "Successfully installed audiomentations-0.33.0 librosa-0.10.2.post1\n",
            "Collecting torch-audiomentations==0.11.0\n",
            "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations==0.11.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cu124)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations==0.11.0)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.14.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2025.7.14)\n",
            "Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Building wheels for collected packages: julius\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=e457ed3453b7e2c45a9161ef0d2591a15e039e65b6a12ed0131f7339f2add05e\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built julius\n",
            "Installing collected packages: primePy, julius, torch-pitch-shift, torch-audiomentations\n",
            "Successfully installed julius-0.2.7 primePy-1.3 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.5\n",
            "Collecting acoustics==0.2.6\n",
            "  Downloading acoustics-0.2.6.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (3.10.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.17.0)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (3.2.3)\n",
            "Building wheels for collected packages: acoustics\n",
            "  Building wheel for acoustics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.6-py3-none-any.whl size=68221 sha256=f17cfad111260d5ffe553c8a83f98a47034bb9c1bf020c8ef3fd2a38b410d9cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/f0/b5/30a5d47708560f77b9167961c7ce13ab1ecf6ac352a3c077c2\n",
            "Successfully built acoustics\n",
            "Installing collected packages: acoustics\n",
            "Successfully installed acoustics-0.2.6\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.8.1 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-cpu==2.8.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorflow_probability==0.16.0\n",
            "  Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (1.17.2)\n",
            "Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "Successfully installed tensorflow_probability-0.16.0\n",
            "Collecting onnx_tf==1.10.0\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting onnx>=1.10.2 (from onnx_tf==1.10.0)\n",
            "  Downloading onnx-1.19.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx_tf==1.10.0) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx_tf==1.10.0)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (4.14.1)\n",
            "Collecting ml_dtypes>=0.5.0 (from onnx>=1.10.2->onnx_tf==1.10.0)\n",
            "  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->onnx_tf==1.10.0) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx_tf==1.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, ml_dtypes, tensorflow-addons, onnx, onnx_tf\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.4\n",
            "    Uninstalling typeguard-4.4.4:\n",
            "      Successfully uninstalled typeguard-4.4.4\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml_dtypes-0.5.4 onnx-1.19.1 onnx_tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Collecting pronouncing==0.2.0\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing==0.2.0)\n",
            "  Downloading cmudict-1.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.23.0)\n",
            "Downloading cmudict-1.1.2-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6234 sha256=e7371a936fd31d175171412dd4895d5100745e99c979335cf590e9a8dd7e2fe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/81/fd/7edbf09827c7a7e2666e870b4c5c6b46c7ebd5defa399698bd\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.1.2 pronouncing-0.2.0\n",
            "Collecting datasets==2.14.6\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.70.15)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.6 fsspec-2023.10.0\n",
            "Collecting deep-phonemizer==0.0.19\n",
            "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (6.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.18.0)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2025.7.14)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (0.45.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer==0.0.19) (3.0.2)\n",
            "Building wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33272 sha256=d63adf46d8d9ff6c207ee08a306e8174124847be5ea18d0a19b2490da2ae1a25\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/cc/01/1c74a1f4e6ba31a42bb82f4e3d852e2f23236fe3e5d589dcf3\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.19\n",
            "--2025-11-28 23:59:48--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A41%3A13Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A40%3A53Z&ske=2025-11-29T00%3A41%3A13Z&sks=b&skv=2018-11-09&sig=0qytC8pLnLhQJZaggfS3SpNbcvqwnpexcuRgSNt4eqI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OCwibmJmIjoxNzY0Mzc0Mzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OFauPKKbYyzify7ilGBdS7w1-mpA_bp-lvnv2-koEn4&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-28 23:59:48--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A41%3A13Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A40%3A53Z&ske=2025-11-29T00%3A41%3A13Z&sks=b&skv=2018-11-09&sig=0qytC8pLnLhQJZaggfS3SpNbcvqwnpexcuRgSNt4eqI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OCwibmJmIjoxNzY0Mzc0Mzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OFauPKKbYyzify7ilGBdS7w1-mpA_bp-lvnv2-koEn4&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1326578 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-11-28 23:59:48 (22.6 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
            "\n",
            "--2025-11-28 23:59:48--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A42%3A24Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A41%3A59Z&ske=2025-11-29T00%3A42%3A24Z&sks=b&skv=2018-11-09&sig=8CwrQpKq2Egt0pxmkUhA7eHbrXUKz41PHdaEJHVe8TE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OCwibmJmIjoxNzY0Mzc0Mzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OFauPKKbYyzify7ilGBdS7w1-mpA_bp-lvnv2-koEn4&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-28 23:59:48--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A42%3A24Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A41%3A59Z&ske=2025-11-29T00%3A42%3A24Z&sks=b&skv=2018-11-09&sig=8CwrQpKq2Egt0pxmkUhA7eHbrXUKz41PHdaEJHVe8TE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OCwibmJmIjoxNzY0Mzc0Mzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OFauPKKbYyzify7ilGBdS7w1-mpA_bp-lvnv2-koEn4&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330312 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-28 23:59:48 (23.7 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
            "\n",
            "--2025-11-28 23:59:48--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A41%3A47Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A41%3A21Z&ske=2025-11-29T00%3A41%3A47Z&sks=b&skv=2018-11-09&sig=dBSW%2Fi1ToFy%2BoNIaTsoBa3Xd9pXMltDA2p6UdowxQDg%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OSwibmJmIjoxNzY0Mzc0Mzg5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.HkW0pgO7cxg-Ifg3y-_lLaFctRvblW620w0xz66Fsjc&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-28 23:59:49--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A41%3A47Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A41%3A21Z&ske=2025-11-29T00%3A41%3A47Z&sks=b&skv=2018-11-09&sig=dBSW%2Fi1ToFy%2BoNIaTsoBa3Xd9pXMltDA2p6UdowxQDg%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OSwibmJmIjoxNzY0Mzc0Mzg5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.HkW0pgO7cxg-Ifg3y-_lLaFctRvblW620w0xz66Fsjc&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1087958 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-28 23:59:49 (22.5 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
            "\n",
            "--2025-11-28 23:59:49--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A47%3A02Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A46%3A39Z&ske=2025-11-29T00%3A47%3A02Z&sks=b&skv=2018-11-09&sig=s%2BFTjI3ZmFJrvkrjLfvh%2Bgf85yU%2B9utXQAqF7ph7rgc%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OSwibmJmIjoxNzY0Mzc0Mzg5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.HkW0pgO7cxg-Ifg3y-_lLaFctRvblW620w0xz66Fsjc&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-28 23:59:49--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-29T00%3A47%3A02Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-28T23%3A46%3A39Z&ske=2025-11-29T00%3A47%3A02Z&sks=b&skv=2018-11-09&sig=s%2BFTjI3ZmFJrvkrjLfvh%2Bgf85yU%2B9utXQAqF7ph7rgc%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDM3NDY4OSwibmJmIjoxNzY0Mzc0Mzg5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.HkW0pgO7cxg-Ifg3y-_lLaFctRvblW620w0xz66Fsjc&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092516 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-11-28 23:59:49 (19.3 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Environment setup\n",
        "\n",
        "# install piper-sample-generator (currently only supports linux systems)\n",
        "!git clone https://github.com/rhasspy/piper-sample-generator\n",
        "!wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "!pip install piper-phonemize\n",
        "!pip install webrtcvad\n",
        "\n",
        "# install openwakeword (full installation to support training)\n",
        "!git clone https://github.com/dscripka/openwakeword\n",
        "!pip install -e ./openwakeword\n",
        "!cd openwakeword\n",
        "\n",
        "# install other dependencies\n",
        "!pip install mutagen==1.47.0\n",
        "!pip install torchinfo==1.8.0\n",
        "!pip install torchmetrics==1.2.0\n",
        "!pip install speechbrain==0.5.14\n",
        "!pip install audiomentations==0.33.0\n",
        "!pip install torch-audiomentations==0.11.0\n",
        "!pip install acoustics==0.2.6\n",
        "!pip install tensorflow-cpu==2.8.1\n",
        "!pip install tensorflow_probability==0.16.0\n",
        "!pip install onnx_tf==1.10.0\n",
        "!pip install pronouncing==0.2.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install deep-phonemizer==0.0.19\n",
        "\n",
        "# Download required models (workaround for Colab)\n",
        "import os\n",
        "os.makedirs(\"./openwakeword/openwakeword/resources/models\")\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX 1: Install piper-tts (missing from environment setup)\n",
        "!pip install piper-tts --quiet\n",
        "\n",
        "# FIX 2: Patch train.py to add model parameter to generate_samples calls\n",
        "file_path = \"openwakeword/openwakeword/train.py\"\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Add model path variable after import\n",
        "if 'piper_model =' not in content:\n",
        "    content = content.replace(\n",
        "        'from generate_samples import generate_samples',\n",
        "        'from generate_samples import generate_samples\\n    piper_model = config.get(\"piper_sample_generator_model_path\", \"piper-sample-generator/models/en_US-libritts_r-medium.pt\")'\n",
        "    )\n",
        "\n",
        "# Fix all generate_samples calls\n",
        "content = content.replace(\n",
        "    '            generate_samples(\\n                text=config[\"target_phrase\"], max_samples=',\n",
        "    '            generate_samples(\\n                text=config[\"target_phrase\"], model=piper_model, max_samples='\n",
        ")\n",
        "content = content.replace(\n",
        "    '            generate_samples(text=adversarial_texts, max_samples=',\n",
        "    '            generate_samples(text=adversarial_texts, model=piper_model, max_samples='\n",
        ")\n",
        "content = content.replace(\n",
        "    '            generate_samples(text=config[\"target_phrase\"], max_samples=',\n",
        "    '            generate_samples(text=config[\"target_phrase\"], model=piper_model, max_samples='\n",
        ")\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Fixes applied!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DnKt6dR4V6C",
        "outputId": "5f52d18f-d613-4fa4-afd5-eece83c9dfbf"
      },
      "id": "8DnKt6dR4V6C",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/13.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/13.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m9.9/13.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m193.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Fixes applied!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOWNLOAD MULTI-LANGUAGE MODELS (run after every restart)\n",
        "import os\n",
        "\n",
        "models_dir = \"piper-sample-generator/models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# These are the working Piper voices (ONNX format)\n",
        "models = {\n",
        "    \"de_DE\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/thorsten/medium/de_DE-thorsten-medium.onnx\",\n",
        "    \"de_DE_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/thorsten/medium/de_DE-thorsten-medium.onnx.json\",\n",
        "\n",
        "    \"es_ES\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/es/es_ES/davefx/medium/es_ES-davefx-medium.onnx\",\n",
        "    \"es_ES_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/es/es_ES/davefx/medium/es_ES-davefx-medium.onnx.json\",\n",
        "\n",
        "    \"fr_FR\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx\",\n",
        "    \"fr_FR_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx.json\",\n",
        "\n",
        "    \"pt_BR\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx\",\n",
        "    \"pt_BR_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx.json\",\n",
        "\n",
        "    \"ru_RU\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx\",\n",
        "    \"ru_RU_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx.json\",\n",
        "\n",
        "    \"zh_CN\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx\",\n",
        "    \"zh_CN_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx.json\",\n",
        "}\n",
        "\n",
        "print(\"Downloading multi-language Piper models...\")\n",
        "print(\"(This takes ~2 minutes)\")\n",
        "\n",
        "for name, url in models.items():\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    output_path = f\"{models_dir}/{filename}\"\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"✓ {filename} (already exists)\")\n",
        "    else:\n",
        "        print(f\"⬇ Downloading {filename}...\")\n",
        "        !wget -q -O {output_path} {url}\n",
        "        if os.path.exists(output_path) and os.path.getsize(output_path) > 1000:\n",
        "            print(f\"  ✓ Done ({os.path.getsize(output_path)/(1024*1024):.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"  ❌ Failed!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Model download complete! Verifying...\")\n",
        "!ls -lh {models_dir}/*.onnx 2>/dev/null | awk '{{print $9, $5}}'\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "wuvdkjDpj1HE",
        "outputId": "5f2d2818-c06e-4e14-b9b8-8a44ed7f6ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wuvdkjDpj1HE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading multi-language Piper models...\n",
            "(This takes ~2 minutes)\n",
            "⬇ Downloading de_DE-thorsten-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading de_DE-thorsten-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading es_ES-davefx-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading es_ES-davefx-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading fr_FR-siwis-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading fr_FR-siwis-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading pt_BR-faber-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading pt_BR-faber-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading ru_RU-dmitri-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading ru_RU-dmitri-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading zh_CN-huayan-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading zh_CN-huayan-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "\n",
            "============================================================\n",
            "Model download complete! Verifying...\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d4c1056e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:42:01.183840Z",
          "start_time": "2023-09-04T13:41:59.752153Z"
        },
        "id": "d4c1056e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import yaml\n",
        "import datasets\n",
        "import scipy\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smDTauKf6IrQ",
        "outputId": "46497b11-d1e2-46f8-f17d-9ae587f3b551"
      },
      "id": "smDTauKf6IrQ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d7a05a",
      "metadata": {
        "id": "e9d7a05a"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52f75cc",
      "metadata": {
        "id": "c52f75cc"
      },
      "source": [
        "When training new openWakeWord models using the automated procedure, four specific types of data are required:\n",
        "\n",
        "1) Synthetic examples of the target word/phrase generated with text-to-speech models\n",
        "\n",
        "2) Synthetic examples of adversarial words/phrases generated with text-to-speech models\n",
        "\n",
        "3) Room impulse reponses and noise/background audio data to augment the synthetic examples and make them more realistic\n",
        "\n",
        "4) Generic \"negative\" audio data that is very unlikely to contain examples of the target word/phrase in the context where the model should detect it. This data can be the original audio data, or precomputed openWakeWord features ready for model training.\n",
        "\n",
        "5) Validation data to use for early-stopping when training the model.\n",
        "\n",
        "For the purposes of this notebook, all five of these sources will either be generated manually or can be obtained from HuggingFace thanks to their excellent `datasets` library and extremely generous hosting policy. Also note that while only a portion of some datasets are downloaded, for the best possible performance it is recommended to download the entire dataset and keep a local copy for future training runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d25a93b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T01:07:17.746749Z",
          "start_time": "2023-09-04T01:07:17.740846Z"
        },
        "id": "d25a93b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "5e44ea9b18624a90a3d35b8299c03c3c",
            "eea618653c7f490c81a89cfb109a5e71",
            "777b82999cf84c1aa34533796c1e711c",
            "83fbfcff83e841459fce71d1846c94f9",
            "1a7b9eb2956f439aa482d658c1ae3f97",
            "4347f16032694b79b0350064c34efdc1",
            "06842584ba4a4180b80693d716cdbf0a",
            "fe70ea28273842248cea5a8ac4e00b33",
            "6b46c15956584717bd951ed6a2eb257b",
            "fb02d8407bf344b5a51017e50713c6e5",
            "2934db122e7944949d595b998033d777",
            "a09b6b1b2b39482c9030c6e379111d66",
            "9832911bf32948f39af4bbf292200538",
            "2fe5a9e352f94d9b9373bcf308f60e5a",
            "90d50a7345ad42a6a3efa40aa19aeb9e",
            "4f513eebdd9c4fb2b1d614fa3e74d575",
            "6fb17f68671c47ffb587213cb36f6391",
            "e0783eb2a25f4cb0ac8ad77542029ec9",
            "693ba0e79b704b7b9e0d16643d72023d",
            "c963783cb869420b95e32bdfe9660f75",
            "30871e05b7a940ecbf78a227804d4870",
            "ffe3514faf5346f9ae0e40d03098f85a"
          ]
        },
        "outputId": "f09891ad-b70f-4ea3-cd7c-99c846154328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/936 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e44ea9b18624a90a3d35b8299c03c3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "HTTP Error 429 thrown while requesting GET https://huggingface.co/api/datasets/davidscripka/MIT_environmental_impulse_responses/tree/b824a1ef2821f112fda0b9cb26e4278c62b425bb/16khz?expand=true&recursive=true&limit=50&cursor=ZXlKbWFXeGxYMjVoYldVaU9pSXhObXRvZWk5b01UQXdYME5zWVhOemNtOXZiVjh5ZEhoMGN5NTNZWFlpTENKMGNtVmxYMjlwWkNJNkltWmtOelV3WVdZME1qRmtOekUxTnpSak9XTTFOamcwTURSaE56VTBaalV4TkRVek5EVTBNVEFpZlE9PToxMDA%3D\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 429 thrown while requesting GET https://huggingface.co/api/datasets/davidscripka/MIT_environmental_impulse_responses/tree/b824a1ef2821f112fda0b9cb26e4278c62b425bb/16khz?expand=true&recursive=true&limit=50&cursor=ZXlKbWFXeGxYMjVoYldVaU9pSXhObXRvZWk5b01UQXdYME5zWVhOemNtOXZiVjh5ZEhoMGN5NTNZWFlpTENKMGNtVmxYMjlwWkNJNkltWmtOelV3WVdZME1qRmtOekUxTnpSak9XTTFOamcwTURSaE56VTBaalV4TkRVek5EVTBNVEFpZlE9PToxMDA%3D\n",
            "Retrying in 1s [Retry 1/20].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/20].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/270 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a09b6b1b2b39482c9030c6e379111d66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "270it [00:45,  5.90it/s]\n"
          ]
        }
      ],
      "source": [
        "# Download room impulse responses collected by MIT\n",
        "# https://mcdermottlab.mit.edu/Reverb/IR_Survey.html\n",
        "\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
        "\n",
        "# Save clips to 16-bit PCM wav files\n",
        "for row in tqdm(rir_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1]\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Check if we have the big files in Drive already\n",
        "drive_backup = '/content/drive/MyDrive/openWakeWord_backup'\n",
        "\n",
        "if os.path.exists(f'{drive_backup}/openwakeword_features_ACAV100M_2000_hrs_16bit.npy'):\n",
        "    print(\"✓ Found backup files in Drive! Copying to workspace...\")\n",
        "\n",
        "    # Copy from Drive instead of downloading\n",
        "    if not os.path.exists('openwakeword_features_ACAV100M_2000_hrs_16bit.npy'):\n",
        "        shutil.copy(f'{drive_backup}/openwakeword_features_ACAV100M_2000_hrs_16bit.npy', '.')\n",
        "    if not os.path.exists('validation_set_features.npy'):\n",
        "        shutil.copy(f'{drive_backup}/validation_set_features.npy', '.')\n",
        "\n",
        "    print(\"✓ Files restored from Drive!\")\n",
        "else:\n",
        "    print(\"No backup found - will download and then backup to Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqBsF5A46sX-",
        "outputId": "728aac7d-1a2e-4bb9-93f7-24c4dbbd9833"
      },
      "id": "FqBsF5A46sX-",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Found backup files in Drive! Copying to workspace...\n",
            "✓ Files restored from Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2c0e178b",
      "metadata": {
        "id": "2c0e178b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642840d1-06a8-46b0-b95c-96e83284ed16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 00:13:19--  https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/bal_train09.tar\n",
            "Resolving huggingface.co (huggingface.co)... 3.170.185.14, 3.170.185.35, 3.170.185.33, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.170.185.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-11-29 00:13:19 ERROR 404: Not Found.\n",
            "\n",
            "tar: This does not look like a tar archive\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            " 99%|█████████▉| 119/120 [00:36<00:00,  3.29it/s]\n"
          ]
        }
      ],
      "source": [
        "## Download noise and background audio\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "fname = \"bal_train09.tar\"\n",
        "out_dir = f\"audioset/{fname}\"\n",
        "link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
        "!wget -O {out_dir} {link}\n",
        "!cd audioset && tar -xvf bal_train09.tar\n",
        "\n",
        "output_dir = \"./audioset_16k\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "# Convert audioset files to 16khz sample rate\n",
        "audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "for row in tqdm(audioset_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset (https://github.com/mdeff/fma)\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "n_hours = 1  # use only 1 hour of clips for this example notebook, recommend increasing for full-scale training\n",
        "for i in tqdm(range(n_hours*3600//30)):  # this works because the FMA dataset is all 30 second clips\n",
        "    row = next(fma_dataset)\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "    i += 1\n",
        "    if i == n_hours*3600//30:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01ec467",
      "metadata": {
        "id": "d01ec467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9bd725-9917-4803-ba1b-a012efc692ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-27 01:30:30--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.40, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013031Z&X-Amz-Expires=3600&X-Amz-Signature=a61fbd21c6761a95cb32ca00543983b2a02687faa53653ba2b3ec4bfde7e0cb8&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1764210631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=Bk4iFZbhEWkFJom4Fb7NIA2nhdojXzD89F0cB9QesaYVyfpdg2uGhK3plGfxllLLqu%7EUtrrxRqUeuW8c7cm8XwjvORYT9FTODFjgG0%7E2gmSLd5jeG4TW%7EpXIkox7dB2c%7EgBM8v5wSz99-eyVBl7yVAwawIwnQo-1Vcio13M6tbf5DIlanFCs9Iz0wHTXRDC3Y4Iqx60I4p%7Ee-4-WEs8KjFRwoAP2UqD%7EXFKztxY%7Ef%7EV8Z1JACkBB365ZcVo8mOT5iP9lpwCy3VhZ57xNDRAZLJpgtR8aWYpxHNgFD4UYtbnn93eQsuQfOQx-ELX-V6aBgOSlinbvM%7En7edArMzPCOw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-27 01:30:31--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013031Z&X-Amz-Expires=3600&X-Amz-Signature=a61fbd21c6761a95cb32ca00543983b2a02687faa53653ba2b3ec4bfde7e0cb8&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1764210631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=Bk4iFZbhEWkFJom4Fb7NIA2nhdojXzD89F0cB9QesaYVyfpdg2uGhK3plGfxllLLqu%7EUtrrxRqUeuW8c7cm8XwjvORYT9FTODFjgG0%7E2gmSLd5jeG4TW%7EpXIkox7dB2c%7EgBM8v5wSz99-eyVBl7yVAwawIwnQo-1Vcio13M6tbf5DIlanFCs9Iz0wHTXRDC3Y4Iqx60I4p%7Ee-4-WEs8KjFRwoAP2UqD%7EXFKztxY%7Ef%7EV8Z1JACkBB365ZcVo8mOT5iP9lpwCy3VhZ57xNDRAZLJpgtR8aWYpxHNgFD4UYtbnn93eQsuQfOQx-ELX-V6aBgOSlinbvM%7En7edArMzPCOw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 108.157.254.62, 108.157.254.55, 108.157.254.25, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|108.157.254.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17280000128 (16G)\n",
            "Saving to: ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’\n",
            "\n",
            "openwakeword_featur 100%[===================>]  16.09G   236MB/s    in 74s     \n",
            "\n",
            "2025-11-27 01:31:45 (222 MB/s) - ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’ saved [17280000128/17280000128]\n",
            "\n",
            "--2025-11-27 01:31:45--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.97, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013145Z&X-Amz-Expires=3600&X-Amz-Signature=d8d722f343df46285962dd4b055e50279904cc3a27fad427d452d45b56e69c0d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1764210705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=Rg8048vBpRbux-lmLimkk4epLrA66Qc8Fp0Romf57KbPYXD46kx80%7ErKpgL-K0ace1nYPTMOiTEdS4kEb-lBlzdVVmTEze%7EKfHgijcoVR3y6jrv8wtvLywvv6kfDrYcI91x4yVIxwtmaLcy1z2CRFtZMDotp6ceqMztmC%7E8O529tU5rV9fNrk3iJmJCP4p8DE9CnNqKKGjbywjVH%7ECwYovIgq9CkyCSu6wpA2qjlrqJiLxKlNobDpWDxfMyOBt8vMgZ6Dx-ZS2aHg1FiV8ez0yCM7OENxVNJqKo4BaLy6Y4RTDJvesKwwO9nFKtXz1gJSDZnpqvwvJhBv67Q7z7ARA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-27 01:31:45--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013145Z&X-Amz-Expires=3600&X-Amz-Signature=d8d722f343df46285962dd4b055e50279904cc3a27fad427d452d45b56e69c0d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1764210705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=Rg8048vBpRbux-lmLimkk4epLrA66Qc8Fp0Romf57KbPYXD46kx80%7ErKpgL-K0ace1nYPTMOiTEdS4kEb-lBlzdVVmTEze%7EKfHgijcoVR3y6jrv8wtvLywvv6kfDrYcI91x4yVIxwtmaLcy1z2CRFtZMDotp6ceqMztmC%7E8O529tU5rV9fNrk3iJmJCP4p8DE9CnNqKKGjbywjVH%7ECwYovIgq9CkyCSu6wpA2qjlrqJiLxKlNobDpWDxfMyOBt8vMgZ6Dx-ZS2aHg1FiV8ez0yCM7OENxVNJqKo4BaLy6Y4RTDJvesKwwO9nFKtXz1gJSDZnpqvwvJhBv67Q7z7ARA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 108.157.254.115, 108.157.254.55, 108.157.254.62, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|108.157.254.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184836608 (176M)\n",
            "Saving to: ‘validation_set_features.npy’\n",
            "\n",
            "validation_set_feat 100%[===================>] 176.27M   325MB/s    in 0.5s    \n",
            "\n",
            "2025-11-27 01:31:46 (325 MB/s) - ‘validation_set_features.npy’ saved [184836608/184836608]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download pre-computed openWakeWord features for training and validation\n",
        "\n",
        "# training set (~2,000 hours from the ACAV100M Dataset)\n",
        "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "\n",
        "# validation set for false positive rate estimation (~11 hours)\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create backup directory in Drive\n",
        "drive_backup = '/content/drive/MyDrive/openWakeWord_backup'\n",
        "os.makedirs(drive_backup, exist_ok=True)\n",
        "\n",
        "# Copy the big files to Drive (only if not already there)\n",
        "files_to_backup = [\n",
        "    'openwakeword_features_ACAV100M_2000_hrs_16bit.npy',\n",
        "    'validation_set_features.npy'\n",
        "]\n",
        "\n",
        "for filename in files_to_backup:\n",
        "    if os.path.exists(filename):\n",
        "        drive_path = f'{drive_backup}/{filename}'\n",
        "        if not os.path.exists(drive_path):\n",
        "            print(f\"Backing up {filename} to Drive... (takes 2-3 min)\")\n",
        "            shutil.copy(filename, drive_path)\n",
        "            print(f\"✓ {filename} backed up!\")\n",
        "        else:\n",
        "            print(f\"✓ {filename} already in Drive\")\n",
        "\n",
        "print(\"\\n✓ All files backed up to Google Drive!\")\n",
        "print(\"Next time, run Cell 2 above to restore instead of re-downloading!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcxGoeIJ60GN",
        "outputId": "e05eaf50-cee6-4168-a499-41fd73726c02"
      },
      "id": "KcxGoeIJ60GN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backing up openwakeword_features_ACAV100M_2000_hrs_16bit.npy to Drive... (takes 2-3 min)\n",
            "✓ openwakeword_features_ACAV100M_2000_hrs_16bit.npy backed up!\n",
            "Backing up validation_set_features.npy to Drive... (takes 2-3 min)\n",
            "✓ validation_set_features.npy backed up!\n",
            "\n",
            "✓ All files backed up to Google Drive!\n",
            "Next time, run Cell 2 above to restore instead of re-downloading!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe82647",
      "metadata": {
        "id": "cfe82647"
      },
      "source": [
        "# Define Training Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e71329",
      "metadata": {
        "id": "b2e71329"
      },
      "source": [
        "For automated model training openWakeWord uses a specially designed training script and a [YAML](https://yaml.org/) configuration file that defines all of the information required for training a new wake word/phrase detection model.\n",
        "\n",
        "It is strongly recommended that you review [the example config file](../examples/custom_model.yml), as each value is fully documented there. For the purposes of this notebook, we'll read in the YAML file to modify certain configuration parameters before saving a new YAML file for training our example model. Specifically:\n",
        "\n",
        "- We'll train a detection model for the phrase \"hey sebastian\"\n",
        "- We'll only generate 5,000 positive and negative examples (to save on time for this example)\n",
        "- We'll only generate 1,000 validation positive and negative examples for early stopping (again to save time)\n",
        "- The model will only be trained for 10,000 steps (larger datasets will benefit from longer training)\n",
        "- We'll reduce the target metrics to account for the small dataset size and limited training.\n",
        "\n",
        "On the topic of target metrics, there are *not* specific guidelines about what these metrics should be in practice, and you will need to conduct testing in your target deployment environment to establish good thresholds. However, from very limited testing the default values in the config file (accuracy >= 0.7, recall >= 0.5, false-positive rate <= 0.2 per hour) seem to produce models with reasonable performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fb0b6e4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T18:11:33.893397Z",
          "start_time": "2023-09-04T18:11:33.878938Z"
        },
        "id": "fb0b6e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6c778d-ca3c-4978-fd67-a84e865d4543"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'my_model',\n",
              " 'target_phrase': ['hey jarvis'],\n",
              " 'custom_negative_phrases': [],\n",
              " 'n_samples': 10000,\n",
              " 'n_samples_val': 2000,\n",
              " 'tts_batch_size': 50,\n",
              " 'augmentation_batch_size': 16,\n",
              " 'piper_sample_generator_path': './piper-sample-generator',\n",
              " 'output_dir': './my_custom_model',\n",
              " 'rir_paths': ['./mit_rirs'],\n",
              " 'background_paths': ['./background_clips'],\n",
              " 'background_paths_duplication_rate': [1],\n",
              " 'false_positive_validation_data_path': './validation_set_features.npy',\n",
              " 'augmentation_rounds': 1,\n",
              " 'feature_data_files': {'ACAV100M_sample': './openwakeword_features_ACAV100M_2000_hrs_16bit.npy'},\n",
              " 'batch_n_per_class': {'ACAV100M_sample': 1024,\n",
              "  'adversarial_negative': 50,\n",
              "  'positive': 50},\n",
              " 'model_type': 'dnn',\n",
              " 'layer_size': 32,\n",
              " 'steps': 50000,\n",
              " 'max_negative_weight': 1500,\n",
              " 'target_false_positives_per_hour': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Load default YAML config file for training\n",
        "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "482cf2d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:07:00.859210Z",
          "start_time": "2023-09-04T15:07:00.841472Z"
        },
        "id": "482cf2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787ff9ea-05b5-4651-e7ca-7f8ea2c709aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Config updated for EXTENDED multi-language training!\n",
            "  - 4500 samples × 3 augmentation rounds = 13500 effective samples\n",
            "  - Layer size: 64\n",
            "  - Training steps: 150,000\n",
            "  - Estimated training time: ~2 hours\n"
          ]
        }
      ],
      "source": [
        "# Modify values in the config and save a new version\n",
        "config[\"target_phrase\"] = [\"Hello James\"]\n",
        "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
        "\n",
        "# MULTI-LANGUAGE TRAINING - ENHANCED VERSION\n",
        "config[\"n_samples\"] = 4500              # Keep existing backed-up samples\n",
        "config[\"n_samples_val\"] = 4500          # Keep existing validation samples\n",
        "config[\"augmentation_rounds\"] = 3       # 3x data augmentation (13,500 effective samples)\n",
        "config[\"layer_size\"] = 64               # Larger model for multi-language capacity\n",
        "config[\"steps\"] = 150000                # Extended training for 10-hour session\n",
        "config[\"target_accuracy\"] = 0.75        # Higher quality threshold\n",
        "config[\"target_recall\"] = 0.5           # Better detection rate\n",
        "config[\"max_negative_weight\"] = 2000    # Allow stronger negative weighting\n",
        "\n",
        "# Data paths (keep as-is)\n",
        "config[\"background_paths\"] = ['./fma']\n",
        "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "with open('my_model.yaml', 'w') as file:\n",
        "    documents = yaml.dump(config, file)\n",
        "\n",
        "print(\"✓ Config updated for EXTENDED multi-language training!\")\n",
        "print(f\"  - {config['n_samples']} samples × 3 augmentation rounds = {config['n_samples']*3} effective samples\")\n",
        "print(f\"  - Layer size: {config['layer_size']}\")\n",
        "print(f\"  - Training steps: {config['steps']:,}\")\n",
        "print(f\"  - Estimated training time: ~2 hours\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6b2ab0",
      "metadata": {
        "id": "aa6b2ab0"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51202c0",
      "metadata": {
        "id": "a51202c0"
      },
      "source": [
        "With the data downloaded and training configuration set, we can now start training the model. We'll do this in parts to better illustrate the sequence, but you can also execute every step at once for a fully automated process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PRE-FLIGHT CHECK: Test piper and verify all models exist\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 PRE-FLIGHT CHECKS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Check piper binary\n",
        "print(\"\\n1️⃣ Testing piper binary...\")\n",
        "piper_path = \"/usr/local/bin/piper\"\n",
        "if not os.path.exists(piper_path):\n",
        "    print(f\"❌ Piper binary not found at {piper_path}\")\n",
        "    print(\"Run FIX 1 cell to install piper!\")\n",
        "else:\n",
        "    print(f\"✓ Piper binary exists\")\n",
        "\n",
        "    # Test with a simple model\n",
        "    test_model = \"piper-sample-generator/models/en_US-libritts_r-medium.onnx\"\n",
        "    if os.path.exists(test_model):\n",
        "        test_file = \"/tmp/piper_test.wav\"\n",
        "        cmd = f'echo \"Hello James\" | {piper_path} --model {test_model} --output_file {test_file}'\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0 and os.path.exists(test_file) and os.path.getsize(test_file) > 100:\n",
        "            size = os.path.getsize(test_file)\n",
        "            print(f\"✓ Piper works! Test file: {size} bytes\")\n",
        "            os.remove(test_file)  # cleanup\n",
        "        else:\n",
        "            print(f\"❌ PIPER FAILED!\")\n",
        "            print(f\"   Return code: {result.returncode}\")\n",
        "            print(f\"   STDERR: {result.stderr[:300]}\")\n",
        "            print(f\"   STDOUT: {result.stdout[:300]}\")\n",
        "            print(\"\\n⚠️ Try installing onnxruntime:\")\n",
        "            print(\"   !pip install onnxruntime\")\n",
        "    else:\n",
        "        print(f\"⚠️ Test model not found: {test_model}\")\n",
        "\n",
        "# 2. Check all language models\n",
        "print(\"\\n2️⃣ Checking language models...\")\n",
        "languages = {\n",
        "    \"en_US\": (\"piper-sample-generator/models/en_US-libritts_r-medium.pt\", \"pt\"),\n",
        "    \"de_DE\": (\"piper-sample-generator/models/de_DE-thorsten-medium.onnx\", \"onnx\"),\n",
        "    \"es_ES\": (\"piper-sample-generator/models/es_ES-davefx-medium.onnx\", \"onnx\"),\n",
        "    \"fr_FR\": (\"piper-sample-generator/models/fr_FR-siwis-medium.onnx\", \"onnx\"),\n",
        "    \"pt_BR\": (\"piper-sample-generator/models/pt_BR-faber-medium.onnx\", \"onnx\"),\n",
        "    \"ru_RU\": (\"piper-sample-generator/models/ru_RU-dmitri-medium.onnx\", \"onnx\"),\n",
        "    \"zh_CN\": (\"piper-sample-generator/models/zh_CN-huayan-medium.onnx\", \"onnx\")\n",
        "}\n",
        "\n",
        "found_models = []\n",
        "missing_models = []\n",
        "\n",
        "for lang, (model_path, model_type) in languages.items():\n",
        "    if os.path.exists(model_path):\n",
        "        size_mb = os.path.getsize(model_path) / (1024*1024)\n",
        "        print(f\"✓ {lang:8} ({model_type}): {size_mb:.1f} MB\")\n",
        "        found_models.append(lang)\n",
        "    else:\n",
        "        print(f\"❌ {lang:8}: NOT FOUND at {model_path}\")\n",
        "        missing_models.append(lang)\n",
        "\n",
        "# 3. Check what models ARE available\n",
        "if missing_models:\n",
        "    print(f\"\\n⚠️ Missing {len(missing_models)} models: {missing_models}\")\n",
        "    print(\"\\nAvailable models in directory:\")\n",
        "    !ls -lh piper-sample-generator/models/*.{pt,onnx} 2>/dev/null | awk '{print $9, $5}'\n",
        "\n",
        "# 4. Check Drive backup status\n",
        "print(\"\\n3️⃣ Checking Drive backup status...\")\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "if os.path.exists(backup_base):\n",
        "    completed = [d for d in os.listdir(backup_base)\n",
        "                 if os.path.isdir(f\"{backup_base}/{d}\")\n",
        "                 and len(os.listdir(f\"{backup_base}/{d}\")) > 0]\n",
        "\n",
        "    if completed:\n",
        "        print(f\"✓ Already completed: {completed}\")\n",
        "        for lang in completed:\n",
        "            file_count = len(os.listdir(f\"{backup_base}/{lang}\"))\n",
        "            print(f\"   {lang}: {file_count} files\")\n",
        "    else:\n",
        "        print(\"  No languages completed yet\")\n",
        "else:\n",
        "    print(\"  Backup directory doesn't exist yet (will be created)\")\n",
        "\n",
        "# 5. Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✓ Models ready: {len(found_models)}/{len(languages)}\")\n",
        "print(f\"  {found_models}\")\n",
        "if missing_models:\n",
        "    print(f\"❌ Models missing: {len(missing_models)}\")\n",
        "    print(f\"  {missing_models}\")\n",
        "    print(\"\\n⚠️ Generation will SKIP missing models\")\n",
        "else:\n",
        "    print(\"✓ ALL MODELS READY!\")\n",
        "\n",
        "print(\"\\nIf piper test failed, run: !pip install onnxruntime\")\n",
        "print(\"Then re-run this cell to verify.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "u-kKYV95g9B0",
        "outputId": "671a87b3-d6c5-48ad-f455-57a04b33b4ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "u-kKYV95g9B0",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🔍 PRE-FLIGHT CHECKS\n",
            "============================================================\n",
            "\n",
            "1️⃣ Testing piper binary...\n",
            "✓ Piper binary exists\n",
            "⚠️ Test model not found: piper-sample-generator/models/en_US-libritts_r-medium.onnx\n",
            "\n",
            "2️⃣ Checking language models...\n",
            "✓ en_US    (pt): 194.6 MB\n",
            "✓ de_DE    (onnx): 60.3 MB\n",
            "✓ es_ES    (onnx): 60.3 MB\n",
            "✓ fr_FR    (onnx): 60.3 MB\n",
            "✓ pt_BR    (onnx): 60.3 MB\n",
            "✓ ru_RU    (onnx): 60.3 MB\n",
            "✓ zh_CN    (onnx): 60.3 MB\n",
            "\n",
            "3️⃣ Checking Drive backup status...\n",
            "✓ Already completed: ['en_US', 'de_DE', 'es_ES', 'fr_FR', 'pt_BR', 'ru_RU', 'zh_CN']\n",
            "   en_US: 2850 files\n",
            "   de_DE: 1610 files\n",
            "   es_ES: 1300 files\n",
            "   fr_FR: 1300 files\n",
            "   pt_BR: 1300 files\n",
            "   ru_RU: 1300 files\n",
            "   zh_CN: 1300 files\n",
            "\n",
            "============================================================\n",
            "📊 SUMMARY\n",
            "============================================================\n",
            "✓ Models ready: 7/7\n",
            "  ['en_US', 'de_DE', 'es_ES', 'fr_FR', 'pt_BR', 'ru_RU', 'zh_CN']\n",
            "✓ ALL MODELS READY!\n",
            "\n",
            "If piper test failed, run: !pip install onnxruntime\n",
            "Then re-run this cell to verify.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f01531fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:50:08.803326Z",
          "start_time": "2023-09-04T13:50:06.790241Z"
        },
        "id": "f01531fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417f94f1-3089-4ec1-b709-d5bf85832197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Already completed languages: ['en_US', 'de_DE', 'es_ES', '.ipynb_checkpoints', 'fr_FR', 'pt_BR', 'ru_RU', 'zh_CN']\n",
            "\n",
            "✓ en_US already backed up, skipping...\n",
            "\n",
            "✓ de_DE already backed up, skipping...\n",
            "\n",
            "✓ es_ES already backed up, skipping...\n",
            "\n",
            "✓ fr_FR already backed up, skipping...\n",
            "\n",
            "✓ pt_BR already backed up, skipping...\n",
            "\n",
            "✓ ru_RU already backed up, skipping...\n",
            "\n",
            "✓ zh_CN already backed up, skipping...\n",
            "\n",
            "============================================================\n",
            "✓ ALL LANGUAGES COMPLETE!\n",
            "============================================================\n",
            "Total samples: 0\n"
          ]
        }
      ],
      "source": [
        "# SAFE Multi-language generation with auto-backup after EACH language\n",
        "import os, uuid, subprocess, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount drive first\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Drive already mounted\")\n",
        "\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "os.makedirs(backup_base, exist_ok=True)\n",
        "\n",
        "languages = {\n",
        "    \"en_US\": (\"piper-sample-generator/models/en_US-libritts_r-medium.pt\", \"pt\"),\n",
        "    \"de_DE\": (\"piper-sample-generator/models/de_DE-thorsten-medium.onnx\", \"onnx\"),\n",
        "    \"es_ES\": (\"piper-sample-generator/models/es_ES-davefx-medium.onnx\", \"onnx\"),\n",
        "    \"fr_FR\": (\"piper-sample-generator/models/fr_FR-siwis-medium.onnx\", \"onnx\"),\n",
        "    \"pt_BR\": (\"piper-sample-generator/models/pt_BR-faber-medium.onnx\", \"onnx\"),\n",
        "    \"ru_RU\": (\"piper-sample-generator/models/ru_RU-dmitri-medium.onnx\", \"onnx\"),\n",
        "    \"zh_CN\": (\"piper-sample-generator/models/zh_CN-huayan-medium.onnx\", \"onnx\")\n",
        "}\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "\n",
        "for d in [positive_train, positive_test]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "samples_per_lang = 650\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"piper-sample-generator\")\n",
        "from generate_samples import generate_samples\n",
        "\n",
        "def generate_with_piper_binary(text, model_path, output_file):\n",
        "    cmd = f'echo \"{text}\" | /usr/local/bin/piper --model {model_path} --output_file {output_file} 2>/dev/null'\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
        "    return result.returncode == 0\n",
        "\n",
        "def backup_language(lang):\n",
        "    \"\"\"Backup one language to Drive immediately\"\"\"\n",
        "    lang_backup = f\"{backup_base}/{lang}\"\n",
        "    os.makedirs(lang_backup, exist_ok=True)\n",
        "\n",
        "    # Copy this language's files\n",
        "    import glob\n",
        "    train_files = glob.glob(f\"{positive_train}/{lang}_*.wav\")\n",
        "    test_files = glob.glob(f\"{positive_test}/{lang}_*.wav\")\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy(f, f\"{lang_backup}/train_{os.path.basename(f)}\")\n",
        "    for f in test_files:\n",
        "        shutil.copy(f, f\"{lang_backup}/test_{os.path.basename(f)}\")\n",
        "\n",
        "    print(f\"   💾 BACKED UP {len(train_files)+len(test_files)} files to Drive!\")\n",
        "\n",
        "# Check what's already done\n",
        "completed = [d for d in os.listdir(backup_base) if os.path.isdir(f\"{backup_base}/{d}\")]\n",
        "print(f\"Already completed languages: {completed}\")\n",
        "\n",
        "# Generate each language with immediate backup\n",
        "for lang, (model_path, model_type) in languages.items():\n",
        "    if lang in completed:\n",
        "        print(f\"\\n✓ {lang} already backed up, skipping...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🎤 {lang}: Generating {samples_per_lang} samples...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # TRAINING\n",
        "    if model_type == \"pt\":\n",
        "        try:\n",
        "            generate_samples(\n",
        "                text=[\"Hello James\"], model=model_path, max_samples=samples_per_lang,\n",
        "                batch_size=50, noise_scales=[0.98], noise_scale_ws=[0.98],\n",
        "                length_scales=[0.75, 1.0, 1.25], output_dir=positive_train,\n",
        "                auto_reduce_batch_size=True,\n",
        "                file_names=[f\"{lang}_{uuid.uuid4().hex}.wav\" for _ in range(samples_per_lang)]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "            continue\n",
        "    else:\n",
        "        success = 0\n",
        "        for i in range(samples_per_lang):\n",
        "            output = f\"{positive_train}/{lang}_{uuid.uuid4().hex}.wav\"\n",
        "            if generate_with_piper_binary(\"Hello James\", model_path, output):\n",
        "                success += 1\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"   Training: {i+1}/{samples_per_lang} ({success} successful)\")\n",
        "\n",
        "    # VALIDATION\n",
        "    if model_type == \"pt\":\n",
        "        try:\n",
        "            generate_samples(\n",
        "                text=[\"Hello James\"], model=model_path, max_samples=samples_per_lang,\n",
        "                batch_size=50, noise_scales=[0.98], noise_scale_ws=[0.98],\n",
        "                length_scales=[0.75, 1.0, 1.25], output_dir=positive_test,\n",
        "                auto_reduce_batch_size=True,\n",
        "                file_names=[f\"{lang}_{uuid.uuid4().hex}.wav\" for _ in range(samples_per_lang)]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "            continue\n",
        "    else:\n",
        "        success = 0\n",
        "        for i in range(samples_per_lang):\n",
        "            output = f\"{positive_test}/{lang}_{uuid.uuid4().hex}.wav\"\n",
        "            if generate_with_piper_binary(\"Hello James\", model_path, output):\n",
        "                success += 1\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"   Validation: {i+1}/{samples_per_lang}\")\n",
        "\n",
        "    # BACKUP IMMEDIATELY\n",
        "    print(f\"\\n   💾 Backing up {lang} to Drive...\")\n",
        "    backup_language(lang)\n",
        "    print(f\"   ✓ {lang} COMPLETE AND SAVED!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ ALL LANGUAGES COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total samples: {len(os.listdir(positive_train))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESTORE: Copy all backed-up samples from Drive to local directories\n",
        "import os, shutil, glob\n",
        "\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"📥 RESTORING ALL SAMPLES FROM DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get all backed up languages\n",
        "backed_up_langs = [d for d in os.listdir(backup_base)\n",
        "                   if os.path.isdir(f\"{backup_base}/{d}\")]\n",
        "\n",
        "print(f\"Found backups: {backed_up_langs}\\n\")\n",
        "\n",
        "total_restored = 0\n",
        "for lang in backed_up_langs:\n",
        "    lang_backup = f\"{backup_base}/{lang}\"\n",
        "    files = os.listdir(lang_backup)\n",
        "\n",
        "    print(f\"Restoring {lang}: {len(files)} files...\")\n",
        "\n",
        "    for filename in files:\n",
        "        src = f\"{lang_backup}/{filename}\"\n",
        "\n",
        "        # Determine if train or test\n",
        "        if filename.startswith(\"train_\"):\n",
        "            dest = f\"{positive_train}/{filename[6:]}\"  # Remove \"train_\" prefix\n",
        "        elif filename.startswith(\"test_\"):\n",
        "            dest = f\"{positive_test}/{filename[5:]}\"  # Remove \"test_\" prefix\n",
        "        else:\n",
        "            print(f\"  ⚠️ Unknown file: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Copy if not already there\n",
        "        if not os.path.exists(dest):\n",
        "            shutil.copy(src, dest)\n",
        "            total_restored += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"✓ RESTORED {total_restored} files from Drive!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training samples: {len(os.listdir(positive_train))}\")\n",
        "print(f\"Test samples: {len(os.listdir(positive_test))}\")\n",
        "print(\"\\nReady for augmentation and training!\")"
      ],
      "metadata": {
        "id": "9FC78ya9mKQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c957d4b-b95e-48a7-e8a5-ede18c620f7d"
      },
      "id": "9FC78ya9mKQN",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "📥 RESTORING ALL SAMPLES FROM DRIVE\n",
            "============================================================\n",
            "Found backups: ['en_US', 'de_DE', 'es_ES', '.ipynb_checkpoints', 'fr_FR', 'pt_BR', 'ru_RU', 'zh_CN']\n",
            "\n",
            "Restoring en_US: 2850 files...\n",
            "Restoring de_DE: 1610 files...\n",
            "Restoring es_ES: 1300 files...\n",
            "Restoring .ipynb_checkpoints: 0 files...\n",
            "Restoring fr_FR: 1300 files...\n",
            "Restoring pt_BR: 1300 files...\n",
            "Restoring ru_RU: 1300 files...\n",
            "Restoring zh_CN: 1300 files...\n",
            "\n",
            "============================================================\n",
            "✓ RESTORED 10960 files from Drive!\n",
            "============================================================\n",
            "Training samples: 5960\n",
            "Test samples: 5000\n",
            "\n",
            "Ready for augmentation and training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 PRE-TRAINING VALIDATION: Check EVERYTHING before starting\n",
        "import os\n",
        "import wave\n",
        "import glob\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 PRE-TRAINING VALIDATION CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_good = True\n",
        "\n",
        "# 1. Check sample directories and counts\n",
        "print(\"\\n1️⃣ Checking sample directories...\")\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "negative_train = f\"{base_dir}/negative_train\"\n",
        "negative_test = f\"{base_dir}/negative_test\"\n",
        "\n",
        "train_files = os.listdir(positive_train) if os.path.exists(positive_train) else []\n",
        "test_files = os.listdir(positive_test) if os.path.exists(positive_test) else []\n",
        "\n",
        "print(f\"   Training samples: {len(train_files)}\")\n",
        "print(f\"   Test samples: {len(test_files)}\")\n",
        "\n",
        "expected_per_lang = 650\n",
        "expected_langs = 7\n",
        "expected_total = expected_per_lang * expected_langs\n",
        "\n",
        "if len(train_files) < expected_total * 0.9:  # Allow 10% tolerance\n",
        "    print(f\"   ⚠️ WARNING: Expected ~{expected_total} training samples, got {len(train_files)}\")\n",
        "    all_good = False\n",
        "else:\n",
        "    print(f\"   ✓ Training sample count looks good!\")\n",
        "\n",
        "if len(test_files) < expected_total * 0.9:\n",
        "    print(f\"   ⚠️ WARNING: Expected ~{expected_total} test samples, got {len(test_files)}\")\n",
        "    all_good = False\n",
        "else:\n",
        "    print(f\"   ✓ Test sample count looks good!\")\n",
        "\n",
        "# 2. Check language distribution\n",
        "print(\"\\n2️⃣ Checking language distribution...\")\n",
        "languages = [\"en_US\", \"de_DE\", \"es_ES\", \"fr_FR\", \"pt_BR\", \"ru_RU\", \"zh_CN\"]\n",
        "lang_counts = {}\n",
        "\n",
        "for lang in languages:\n",
        "    train_count = len([f for f in train_files if f.startswith(lang)])\n",
        "    test_count = len([f for f in test_files if f.startswith(lang)])\n",
        "    lang_counts[lang] = (train_count, test_count)\n",
        "\n",
        "    total = train_count + test_count\n",
        "    if total > 0:\n",
        "        print(f\"   {lang}: {train_count} train + {test_count} test = {total} total\")\n",
        "    else:\n",
        "        print(f\"   ❌ {lang}: NO SAMPLES FOUND!\")\n",
        "        all_good = False\n",
        "\n",
        "# 3. Check sample rates\n",
        "print(\"\\n3️⃣ Checking sample rates (should be 16000 Hz)...\")\n",
        "sample_rates = {}\n",
        "for filename in train_files[:5]:  # Check first 5 files\n",
        "    filepath = f\"{positive_train}/{filename}\"\n",
        "    try:\n",
        "        with wave.open(filepath, 'rb') as wav:\n",
        "            rate = wav.getframerate()\n",
        "            sample_rates[rate] = sample_rates.get(rate, 0) + 1\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️ Error reading {filename}: {e}\")\n",
        "        all_good = False\n",
        "\n",
        "if sample_rates:\n",
        "    for rate, count in sample_rates.items():\n",
        "        if rate == 16000:\n",
        "            print(f\"   ✓ Sample rate: {rate} Hz (correct)\")\n",
        "        else:\n",
        "            print(f\"   ❌ Sample rate: {rate} Hz (WRONG! Should be 16000 Hz)\")\n",
        "            print(f\"   → Run FIX 3 (resample) cell before training!\")\n",
        "            all_good = False\n",
        "\n",
        "# 4. Check file sizes (detect empty files)\n",
        "print(\"\\n4️⃣ Checking for empty/corrupted files...\")\n",
        "empty_files = 0\n",
        "small_files = 0\n",
        "for filename in train_files[:100]:  # Sample 100 files\n",
        "    filepath = f\"{positive_train}/{filename}\"\n",
        "    size = os.path.getsize(filepath)\n",
        "    if size == 0:\n",
        "        empty_files += 1\n",
        "    elif size < 1000:  # Less than 1KB is suspicious\n",
        "        small_files += 1\n",
        "\n",
        "if empty_files > 0:\n",
        "    print(f\"   ❌ Found {empty_files} empty files!\")\n",
        "    all_good = False\n",
        "elif small_files > 5:\n",
        "    print(f\"   ⚠️ Found {small_files} suspiciously small files\")\n",
        "else:\n",
        "    print(f\"   ✓ No empty files detected\")\n",
        "\n",
        "# 5. Check background/noise data\n",
        "print(\"\\n5️⃣ Checking background audio datasets...\")\n",
        "required_dirs = {\n",
        "    \"./audioset_16k\": \"AudioSet background noise\",\n",
        "    \"./fma\": \"FMA music dataset\",\n",
        "    \"./mit_rirs\": \"MIT room impulse responses\"\n",
        "}\n",
        "\n",
        "for dir_path, description in required_dirs.items():\n",
        "    if os.path.exists(dir_path):\n",
        "        file_count = len([f for f in os.listdir(dir_path) if f.endswith('.wav')])\n",
        "        print(f\"   ✓ {description}: {file_count} files\")\n",
        "    else:\n",
        "        print(f\"   ❌ {description}: NOT FOUND at {dir_path}\")\n",
        "        all_good = False\n",
        "\n",
        "# 6. Check feature data file (16GB embeddings)\n",
        "print(\"\\n6️⃣ Checking feature embedding file...\")\n",
        "feature_file = \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
        "if os.path.exists(feature_file):\n",
        "    size_gb = os.path.getsize(feature_file) / (1024**3)\n",
        "    print(f\"   ✓ Feature file exists: {size_gb:.1f} GB\")\n",
        "else:\n",
        "    print(f\"   ❌ Feature file NOT FOUND: {feature_file}\")\n",
        "    all_good = False\n",
        "\n",
        "# 7. Check config file\n",
        "print(\"\\n7️⃣ Checking training config...\")\n",
        "if os.path.exists('my_model.yaml'):\n",
        "    import yaml\n",
        "    with open('my_model.yaml', 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "\n",
        "    print(f\"   Target phrase: {config.get('target_phrase', 'NOT SET')}\")\n",
        "    print(f\"   Model name: {config.get('model_name', 'NOT SET')}\")\n",
        "    print(f\"   Training steps: {config.get('steps', 'NOT SET')}\")\n",
        "    print(f\"   n_samples: {config.get('n_samples', 'NOT SET')}\")\n",
        "\n",
        "    if config.get('target_phrase') != ['Hello James']:\n",
        "        print(f\"   ⚠️ Target phrase mismatch!\")\n",
        "        all_good = False\n",
        "    else:\n",
        "        print(f\"   ✓ Config looks good\")\n",
        "else:\n",
        "    print(f\"   ❌ Config file 'my_model.yaml' NOT FOUND!\")\n",
        "    all_good = False\n",
        "\n",
        "# 8. Check Python environment\n",
        "print(\"\\n8️⃣ Checking Python packages...\")\n",
        "try:\n",
        "    import torch\n",
        "    import torchaudio\n",
        "    import openwakeword\n",
        "    print(f\"   ✓ PyTorch: {torch.__version__}\")\n",
        "    print(f\"   ✓ torchaudio: {torchaudio.__version__}\")\n",
        "    print(f\"   ✓ openwakeword: installed\")\n",
        "except ImportError as e:\n",
        "    print(f\"   ❌ Missing package: {e}\")\n",
        "    all_good = False\n",
        "\n",
        "# FINAL VERDICT\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_good:\n",
        "    print(\"✅ ALL CHECKS PASSED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"🚀 READY TO TRAIN!\")\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. Run Step 2: Data augmentation + feature extraction (~15 mins)\")\n",
        "    print(\"2. Run Step 3: Train model (~30-60 mins on A100)\")\n",
        "    print(\"3. Download your .tflite model!\")\n",
        "else:\n",
        "    print(\"❌ VALIDATION FAILED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"⚠️ FIX THE ISSUES ABOVE BEFORE TRAINING!\")\n",
        "    print(\"\\nCommon fixes:\")\n",
        "    print(\"- Run RESTORE cell to get all samples from Drive\")\n",
        "    print(\"- Run FIX 3 (resample) if sample rate is wrong\")\n",
        "    print(\"- Re-run download cells for missing datasets\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "UA-FRbBbmjS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c56405e-99ff-40e5-abdc-510f3510ed6e"
      },
      "id": "UA-FRbBbmjS3",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🔍 PRE-TRAINING VALIDATION CHECK\n",
            "============================================================\n",
            "\n",
            "1️⃣ Checking sample directories...\n",
            "   Training samples: 5960\n",
            "   Test samples: 5000\n",
            "   ✓ Training sample count looks good!\n",
            "   ✓ Test sample count looks good!\n",
            "\n",
            "2️⃣ Checking language distribution...\n",
            "   en_US: 1750 train + 1100 test = 2850 total\n",
            "   de_DE: 960 train + 650 test = 1610 total\n",
            "   es_ES: 650 train + 650 test = 1300 total\n",
            "   fr_FR: 650 train + 650 test = 1300 total\n",
            "   pt_BR: 650 train + 650 test = 1300 total\n",
            "   ru_RU: 650 train + 650 test = 1300 total\n",
            "   zh_CN: 650 train + 650 test = 1300 total\n",
            "\n",
            "3️⃣ Checking sample rates (should be 16000 Hz)...\n",
            "   ❌ Sample rate: 22050 Hz (WRONG! Should be 16000 Hz)\n",
            "   → Run FIX 3 (resample) cell before training!\n",
            "\n",
            "4️⃣ Checking for empty/corrupted files...\n",
            "   ✓ No empty files detected\n",
            "\n",
            "5️⃣ Checking background audio datasets...\n",
            "   ✓ AudioSet background noise: 0 files\n",
            "   ✓ FMA music dataset: 120 files\n",
            "   ✓ MIT room impulse responses: 270 files\n",
            "\n",
            "6️⃣ Checking feature embedding file...\n",
            "   ✓ Feature file exists: 16.1 GB\n",
            "\n",
            "7️⃣ Checking training config...\n",
            "   Target phrase: ['Hello James']\n",
            "   Model name: Hello_James\n",
            "   Training steps: 150000\n",
            "   n_samples: 4500\n",
            "   ✓ Config looks good\n",
            "\n",
            "8️⃣ Checking Python packages...\n",
            "   ✓ PyTorch: 2.6.0+cu124\n",
            "   ✓ torchaudio: 2.6.0+cu124\n",
            "   ✓ openwakeword: installed\n",
            "\n",
            "============================================================\n",
            "❌ VALIDATION FAILED!\n",
            "============================================================\n",
            "⚠️ FIX THE ISSUES ABOVE BEFORE TRAINING!\n",
            "\n",
            "Common fixes:\n",
            "- Run RESTORE cell to get all samples from Drive\n",
            "- Run FIX 3 (resample) if sample rate is wrong\n",
            "- Re-run download cells for missing datasets\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🆘 BACKUP: Download alternative background audio if augmentation fails\n",
        "# Run this ONLY if you get StopIteration during augmentation\n",
        "\n",
        "import os\n",
        "import datasets\n",
        "import scipy.io.wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_dir = \"./audioset_16k\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DOWNLOADING BACKUP BACKGROUND AUDIO\")\n",
        "print(\"Source: FreeSound dataset (alternative to AudioSet)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Option 1: Download more FMA music (fast, reliable)\n",
        "print(\"\\n📥 Downloading additional FMA tracks...\")\n",
        "fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "# Download 3 more hours (vs the 1 hour we have)\n",
        "target_clips = 360  # 3 hours of 30-second clips\n",
        "current_fma = len([f for f in os.listdir(\"./fma\") if f.endswith('.wav')])\n",
        "\n",
        "print(f\"Current FMA clips: {current_fma}\")\n",
        "print(f\"Downloading {target_clips} more clips (~3 hours)...\")\n",
        "\n",
        "for i in tqdm(range(target_clips)):\n",
        "    try:\n",
        "        row = next(fma_dataset)\n",
        "        name = f\"fma_extra_{i:05d}.wav\"\n",
        "        scipy.io.wavfile.write(\n",
        "            os.path.join(\"./fma\", name),\n",
        "            16000,\n",
        "            (row['audio']['array']*32767).astype(np.int16)\n",
        "        )\n",
        "    except StopIteration:\n",
        "        print(f\"Dataset exhausted at {i} clips\")\n",
        "        break\n",
        "\n",
        "final_count = len([f for f in os.listdir(\"./fma\") if f.endswith('.wav')])\n",
        "print(f\"\\n✅ FMA now has {final_count} clips!\")\n",
        "\n",
        "# Option 2: Use speech data as background (adds variety)\n",
        "print(\"\\n📥 Downloading CommonVoice samples for speech background...\")\n",
        "try:\n",
        "    cv_dataset = datasets.load_dataset(\n",
        "        \"mozilla-foundation/common_voice_11_0\",\n",
        "        \"en\",\n",
        "        split=\"train\",\n",
        "        streaming=True,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    cv_dataset = iter(cv_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "    for i in tqdm(range(200)):  # Add 200 speech samples\n",
        "        try:\n",
        "            row = next(cv_dataset)\n",
        "            name = f\"speech_{i:05d}.wav\"\n",
        "            scipy.io.wavfile.write(\n",
        "                os.path.join(\"./fma\", name),\n",
        "                16000,\n",
        "                (row['audio']['array']*32767).astype(np.int16)\n",
        "            )\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    print(f\"✅ Added speech samples!\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  CommonVoice download failed (optional): {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"✅ BACKUP COMPLETE!\")\n",
        "print(f\"Total background files: {len(os.listdir('./fma'))}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nNow re-run Step 2 (augmentation)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1618kIZ63Xpv",
        "outputId": "c8c0fb6a-6a5e-445a-c805-d72068f18b21"
      },
      "id": "1618kIZ63Xpv",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DOWNLOADING BACKUP BACKGROUND AUDIO\n",
            "Source: FreeSound dataset (alternative to AudioSet)\n",
            "============================================================\n",
            "\n",
            "📥 Downloading additional FMA tracks...\n",
            "Current FMA clips: 120\n",
            "Downloading 360 more clips (~3 hours)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 360/360 [01:46<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ FMA now has 480 clips!\n",
            "\n",
            "📥 Downloading CommonVoice samples for speech background...\n",
            "⚠️  CommonVoice download failed (optional): Couldn't find a dataset script at /content/mozilla-foundation/common_voice_11_0/common_voice_11_0.py or any data file in the same directory. Couldn't find 'mozilla-foundation/common_voice_11_0' on the Hugging Face Hub either: FileNotFoundError: Dataset 'mozilla-foundation/common_voice_11_0' doesn't exist on the Hub. If the repo is private or gated, make sure to log in with `huggingface-cli login`.\n",
            "\n",
            "============================================================\n",
            "✅ BACKUP COMPLETE!\n",
            "Total background files: 480\n",
            "============================================================\n",
            "\n",
            "Now re-run Step 2 (augmentation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE old features to force regeneration with new augmentation_rounds\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "\n",
        "print(\"Deleting old augmented data...\")\n",
        "\n",
        "# Delete feature files\n",
        "for feature_file in [\"positive_features_train.npy\", \"positive_features_test.npy\"]:\n",
        "    path = f\"{base_dir}/{feature_file}\"\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "        print(f\"✓ Deleted {feature_file}\")\n",
        "    else:\n",
        "        print(f\"  {feature_file} not found (already deleted)\")\n",
        "\n",
        "# Delete negative directories (will be regenerated)\n",
        "for neg_dir in [\"negative_train\", \"negative_test\"]:\n",
        "    path = f\"{base_dir}/{neg_dir}\"\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "        print(f\"✓ Deleted {neg_dir}/\")\n",
        "    else:\n",
        "        print(f\"  {neg_dir}/ not found (already deleted)\")\n",
        "\n",
        "print(\"\\n✓ Ready for fresh augmentation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3b0ztrLx1IG",
        "outputId": "11d49493-6167-460d-c182-bb2806651611"
      },
      "id": "O3b0ztrLx1IG",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting old augmented data...\n",
            "✓ Deleted positive_features_train.npy\n",
            "✓ Deleted positive_features_test.npy\n",
            "✓ Deleted negative_train/\n",
            "✓ Deleted negative_test/\n",
            "\n",
            "✓ Ready for fresh augmentation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATE ADVERSARIAL NEGATIVE CLIPS\n",
        "# This creates similar-sounding phrases like \"hello jane\", \"yellow james\", etc.\n",
        "import sys\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Generating adversarial negative clips...\")\n",
        "print(\"This will take ~5-10 minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --generate_clips\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ Adversarial clips generated!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nVerifying negative samples were created:\")\n",
        "!ls -lh {base_dir}/negative_train/ | head -5\n",
        "!ls -lh {base_dir}/negative_test/ | head -5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4lgan_Nx5pO",
        "outputId": "42750e46-4061-4ce3-8ed2-aa219617b726"
      },
      "id": "F4lgan_Nx5pO",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Generating adversarial negative clips...\n",
            "This will take ~5-10 minutes\n",
            "============================================================\n",
            "2025-11-29 00:22:04.492039: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-29 00:22:04.507740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764375724.526481   21092 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764375724.532941   21092 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-11-29 00:22:04.554351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "WARNING:root:Skipping generation of positive clips for training, as ~4500 already exist\n",
            "WARNING:root:Skipping generation of positive clips testing, as ~4500 already exist\n",
            "\n",
            "============================================================\n",
            "✓ Adversarial clips generated!\n",
            "============================================================\n",
            "\n",
            "Verifying negative samples were created:\n",
            "total 232M\n",
            "-rw-r--r-- 1 root root  39K Nov 29 00:23 000288859ed34d40ac204df04ef6600f.wav\n",
            "-rw-r--r-- 1 root root  44K Nov 29 00:22 004340217a75429f9953f18577bd2dfe.wav\n",
            "-rw-r--r-- 1 root root  43K Nov 29 00:23 006cb4ccd9ad476086bf155facea10a1.wav\n",
            "-rw-r--r-- 1 root root  40K Nov 29 00:23 0078f94e6e69498a87007b97b77a4ff9.wav\n",
            "total 234M\n",
            "-rw-r--r-- 1 root root  44K Nov 29 00:24 0.wav\n",
            "-rw-r--r-- 1 root root  63K Nov 29 00:24 1000.wav\n",
            "-rw-r--r-- 1 root root  58K Nov 29 00:24 1001.wav\n",
            "-rw-r--r-- 1 root root  49K Nov 29 00:24 1002.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK sample rate of adversarial clips\n",
        "import scipy.io.wavfile as wavfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "\n",
        "print(\"Checking sample rates of adversarial clips...\")\n",
        "\n",
        "# Check a few negative samples\n",
        "for subdir in ['negative_train', 'negative_test']:\n",
        "    path = f\"{base_dir}/{subdir}\"\n",
        "    files = glob.glob(f\"{path}/*.wav\")[:3]  # Check first 3 files\n",
        "\n",
        "    print(f\"\\n{subdir}:\")\n",
        "    for f in files:\n",
        "        sr, data = wavfile.read(f)\n",
        "        print(f\"  {os.path.basename(f)}: {sr} Hz\")"
      ],
      "metadata": {
        "id": "KI2X8R160T0V"
      },
      "id": "KI2X8R160T0V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX 3 CORRECTED: Resample all clips from 22050 Hz to 16000 Hz (with error handling)\n",
        "import os\n",
        "import scipy.io.wavfile as wavfile\n",
        "import scipy.signal\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "\n",
        "# First, delete the old features file created with wrong sample rate\n",
        "features_file = f\"{base_dir}/positive_features_train.npy\"\n",
        "if os.path.exists(features_file):\n",
        "    os.remove(features_file)\n",
        "    print(f\"✓ Deleted old features file\\n\")\n",
        "\n",
        "# Resample all audio files (with error handling for corrupted files)\n",
        "for subdir in ['positive_train', 'positive_test', 'negative_train', 'negative_test']:\n",
        "    path = f\"{base_dir}/{subdir}\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"⚠️  {subdir} doesn't exist, skipping...\")\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "    print(f\"Resampling {len(files)} files in {subdir}...\")\n",
        "\n",
        "    corrupted = 0\n",
        "    for filename in tqdm(files):\n",
        "        filepath = os.path.join(path, filename)\n",
        "\n",
        "        try:\n",
        "            # Check file size first (catch empty files)\n",
        "            if os.path.getsize(filepath) < 1000:  # Less than 1KB = corrupted\n",
        "                os.remove(filepath)\n",
        "                corrupted += 1\n",
        "                continue\n",
        "\n",
        "            sr, data = wavfile.read(filepath)\n",
        "\n",
        "            if sr != 16000:\n",
        "                # Resample to 16000 Hz\n",
        "                number_of_samples = round(len(data) * 16000 / sr)\n",
        "                resampled = scipy.signal.resample(data, number_of_samples)\n",
        "                wavfile.write(filepath, 16000, resampled.astype(data.dtype))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Delete corrupted file\n",
        "            os.remove(filepath)\n",
        "            corrupted += 1\n",
        "\n",
        "    if corrupted > 0:\n",
        "        print(f\"  ⚠️  Deleted {corrupted} corrupted files\")\n",
        "\n",
        "print(\"\\n✓ All clips resampled to 16000 Hz!\")\n",
        "print(\"Now continue with next step!\")"
      ],
      "metadata": {
        "id": "I4lh_UYL7-kx",
        "outputId": "be688521-1fc8-48d4-9f73-0b693b307e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I4lh_UYL7-kx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling 5960 files in positive_train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5960/5960 [00:00<00:00, 22291.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling 5000 files in positive_test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:05<00:00, 939.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ⚠️  Deleted 1 corrupted files\n",
            "Resampling 4500 files in negative_train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 3366/4500 [00:14<00:04, 229.50it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE cleanup if augmentation fails to remove all partial files.\n",
        "import os\n",
        "import glob\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "\n",
        "print(\"Cleaning up ALL partial augmentation files...\")\n",
        "\n",
        "# Delete ALL .npy feature files (positive AND negative)\n",
        "npy_files = glob.glob(f\"{base_dir}/*.npy\")\n",
        "if npy_files:\n",
        "    for npy_file in npy_files:\n",
        "        os.remove(npy_file)\n",
        "        print(f\"✓ Deleted {os.path.basename(npy_file)}\")\n",
        "else:\n",
        "    print(\"  No .npy files found\")\n",
        "\n",
        "# Also check for any augmented wav files (shouldn't exist, but just in case)\n",
        "for subdir in ['positive_train', 'positive_test', 'negative_train', 'negative_test']:\n",
        "    aug_path = f\"{base_dir}/{subdir}_augmented\"\n",
        "    if os.path.exists(aug_path):\n",
        "        import shutil\n",
        "        shutil.rmtree(aug_path)\n",
        "        print(f\"✓ Deleted {subdir}_augmented/\")\n",
        "\n",
        "print(\"\\n✅ Complete cleanup done - safe to retry augmentation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9UIWq8z09tf",
        "outputId": "5422e213-4a99-4877-a791-129c410595d4"
      },
      "id": "v9UIWq8z09tf",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up partial augmentation files...\n",
            "  positive_features_train.npy - not found (ok)\n",
            "  positive_features_test.npy - not found (ok)\n",
            "\n",
            "✓ Safe to re-run augmentation now!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 PRE-AUGMENTATION VALIDATION: Check EVERYTHING before starting\n",
        "import os\n",
        "import wave\n",
        "import glob\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 PRE-AUGMENTATION VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "all_good = True\n",
        "\n",
        "# 1. Check all sample directories exist with correct counts\n",
        "print(\"\\n1️⃣ Checking sample directories...\")\n",
        "expected = {\n",
        "    'positive_train': 10000,\n",
        "    'positive_test': 4999,\n",
        "    'negative_train': 4500,\n",
        "    'negative_test': 4500\n",
        "}\n",
        "\n",
        "for subdir, expected_count in expected.items():\n",
        "    path = f\"{base_dir}/{subdir}\"\n",
        "    if os.path.exists(path):\n",
        "        count = len([f for f in os.listdir(path) if f.endswith('.wav')])\n",
        "        if count >= expected_count * 0.95:  # Allow 5% tolerance\n",
        "            print(f\"  ✓ {subdir}: {count} files\")\n",
        "        else:\n",
        "            print(f\"  ⚠️  {subdir}: {count} files (expected ~{expected_count})\")\n",
        "            all_good = False\n",
        "    else:\n",
        "        print(f\"  ❌ {subdir}: MISSING\")\n",
        "        all_good = False\n",
        "\n",
        "# 2. Check sample rates (random sampling)\n",
        "print(\"\\n2️⃣ Checking sample rates (16000 Hz required)...\")\n",
        "for subdir in ['positive_train', 'positive_test', 'negative_train', 'negative_test']:\n",
        "    path = f\"{base_dir}/{subdir}\"\n",
        "    if os.path.exists(path):\n",
        "        files = glob.glob(f\"{path}/*.wav\")[:5]  # Check 5 random files\n",
        "        bad_files = 0\n",
        "        for f in files:\n",
        "            try:\n",
        "                with wave.open(f, 'rb') as wav:\n",
        "                    sr = wav.getframerate()\n",
        "                    if sr != 16000:\n",
        "                        bad_files += 1\n",
        "            except:\n",
        "                bad_files += 1\n",
        "\n",
        "        if bad_files == 0:\n",
        "            print(f\"  ✓ {subdir}: All checked samples at 16000 Hz\")\n",
        "        else:\n",
        "            print(f\"  ❌ {subdir}: Found {bad_files} files with wrong sample rate!\")\n",
        "            all_good = False\n",
        "\n",
        "# 3. Check background audio exists\n",
        "print(\"\\n3️⃣ Checking background audio...\")\n",
        "for bg_path in ['./audioset_16k', './fma', './mit_rirs']:\n",
        "    if os.path.exists(bg_path):\n",
        "        count = len(glob.glob(f\"{bg_path}/*.wav\"))\n",
        "        print(f\"  ✓ {bg_path}: {count} files\")\n",
        "        if count == 0:\n",
        "            print(f\"    ⚠️  Directory exists but is EMPTY!\")\n",
        "            all_good = False\n",
        "    else:\n",
        "        print(f\"  ❌ {bg_path}: MISSING\")\n",
        "        all_good = False\n",
        "\n",
        "# 4. Check config file\n",
        "print(\"\\n4️⃣ Checking config file...\")\n",
        "if os.path.exists('my_model.yaml'):\n",
        "    print(f\"  ✓ my_model.yaml exists\")\n",
        "    !grep -E \"(n_samples|augmentation_rounds|layer_size|steps):\" my_model.yaml\n",
        "else:\n",
        "    print(f\"  ❌ my_model.yaml MISSING\")\n",
        "    all_good = False\n",
        "\n",
        "# 5. Check no feature files exist (should be clean slate)\n",
        "print(\"\\n5️⃣ Checking no old features exist...\")\n",
        "for feature in ['positive_features_train.npy', 'positive_features_test.npy']:\n",
        "    path = f\"{base_dir}/{feature}\"\n",
        "    if os.path.exists(path):\n",
        "        print(f\"  ⚠️  {feature} exists (will be overwritten)\")\n",
        "    else:\n",
        "        print(f\"  ✓ {feature} not found (clean slate)\")\n",
        "\n",
        "# Final verdict\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_good:\n",
        "    print(\"✅ ALL CHECKS PASSED - READY FOR AUGMENTATION!\")\n",
        "else:\n",
        "    print(\"❌ ISSUES FOUND - FIX BEFORE AUGMENTATION!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "JJEt4rm-1aZ2"
      },
      "id": "JJEt4rm-1aZ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afeedae4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:56:08.781018Z",
          "start_time": "2023-09-04T13:55:40.203515Z"
        },
        "id": "afeedae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13f81f4-db81-4706-a5b1-ef09e047356f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-28 23:43:21.238533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764373401.260339   57677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764373401.266801   57677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = PitchShift(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = BandStopFilter(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddColoredNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddBackgroundNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Gain(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Compose(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
            "  warnings.warn(\n",
            "Computing features:  91% 566/625 [05:40<00:35,  1.66it/s]"
          ]
        }
      ],
      "source": [
        "# Step 2: Augment the generated clips\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9ad81ea0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:11:14.742260Z",
          "start_time": "2023-09-04T15:07:03.755159Z"
        },
        "id": "9ad81ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43ff9dc-acfa-450f-89d4-9e96dd9de9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x7d816bcedd00>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 199, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/openwakeword/openwakeword/train.py\", line 4, in <module>\n",
            "    import torchmetrics\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchmetrics/__init__.py\", line 14, in <module>\n",
            "    from torchmetrics import functional  # noqa: E402\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/__init__.py\", line 120, in <module>\n",
            "    from torchmetrics.functional.text._deprecated import _bleu_score as bleu_score\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/text/__init__.py\", line 50, in <module>\n",
            "    from torchmetrics.functional.text.bert import bert_score  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/text/bert.py\", line 23, in <module>\n",
            "    from torchmetrics.functional.text.helper_embedding_metric import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchmetrics/functional/text/helper_embedding_metric.py\", line 27, in <module>\n",
            "    from transformers import AutoModelForMaskedLM, AutoTokenizer, PreTrainedModel, PreTrainedTokenizerBase\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 50, in <module>\n",
            "    from torchao.quantization import Int4WeightOnlyConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/__init__.py\", line 41, in <module>\n",
            "    from torchao.quantization import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/quantization/__init__.py\", line 6, in <module>\n",
            "    from .autoquant import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/quantization/autoquant.py\", line 11, in <module>\n",
            "    from torchao.dtypes import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/dtypes/__init__.py\", line 1, in <module>\n",
            "    from . import affine_quantized_tensor_ops\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/dtypes/affine_quantized_tensor_ops.py\", line 11, in <module>\n",
            "    from torchao.dtypes.affine_quantized_tensor import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/dtypes/affine_quantized_tensor.py\", line 17, in <module>\n",
            "    from torchao.quantization.quant_primitives import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/quantization/quant_primitives.py\", line 202, in <module>\n",
            "    register_custom_op = _register_custom_op(quant_lib)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchao/utils.py\", line 205, in _register_custom_op\n",
            "    from torch._inductor.decomposition import register_decomposition\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/decomposition.py\", line 94, in <module>\n",
            "    decompositions = {**core_aten_decompositions(), **inductor_decompositions}\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_decomp/__init__.py\", line 291, in core_aten_decompositions\n",
            "    return default_decompositions()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/export/exported_program.py\", line 352, in default_decompositions\n",
            "    return CustomDecompTable()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/export/decomp_utils.py\", line 40, in __init__\n",
            "    for op in _collect_all_valid_cia_ops_for_aten_namespace():\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_export/utils.py\", line 1072, in _collect_all_valid_cia_ops_for_aten_namespace\n",
            "    return _collect_all_valid_cia_ops_for_namespace(\"aten\")\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_export/utils.py\", line 1086, in _collect_all_valid_cia_ops_for_namespace\n",
            "    op_overload = getattr(op_packet, overload)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1083, in __getattr__\n",
            "    op_dk_tags = torch._C._get_operation_overload(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Train model\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX: Downgrade onnx to compatible version\n",
        "!pip install -q onnx==1.12.0\n",
        "\n",
        "# Now convert to TFLite\n",
        "import onnx\n",
        "import logging\n",
        "import tempfile\n",
        "from onnx_tf.backend import prepare\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "    onnx_model = onnx.load(onnx_model_path)\n",
        "    tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        tflite_model = converter.convert()\n",
        "        logging.info(f\"####\\nSaving tflite model to '{output_path}'\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "    return output_path\n",
        "\n",
        "# Convert your model\n",
        "model_name = \"Hello_James\"\n",
        "onnx_path = f\"my_custom_model/{model_name}.onnx\"\n",
        "tflite_path = f\"my_custom_model/{model_name}.tflite\"\n",
        "\n",
        "print(f\"Converting {onnx_path}...\")\n",
        "convert_onnx_to_tflite(onnx_path, tflite_path)\n",
        "\n",
        "print(f\"\\n✓ Conversion complete!\")\n",
        "print(f\"ONNX model: {onnx_path} ({os.path.getsize(onnx_path)/1024:.1f} KB)\")\n",
        "print(f\"TFLite model: {tflite_path} ({os.path.getsize(tflite_path)/1024:.1f} KB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "wV8APOyhvEia",
        "outputId": "0fb9dd70-25aa-45ff-8531-564a5fda43bd"
      },
      "id": "wV8APOyhvEia",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for onnx (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for onnx\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (onnx)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'mapping' from 'onnx' (/usr/local/lib/python3.11/dist-packages/onnx/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-3419999321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_rep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorflowRep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_unique_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupports_device\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon_supports_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/common/data_type.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'mapping' from 'onnx' (/usr/local/lib/python3.11/dist-packages/onnx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "JSKWWLalnYzR",
      "metadata": {
        "id": "JSKWWLalnYzR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "49ec4d1c-1a3b-492a-c578-4beacd0b97ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'mapping' from 'onnx' (/usr/local/lib/python3.11/dist-packages/onnx/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-2637122192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mconvert_onnx_to_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"my_custom_model/{config['model_name']}.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"my_custom_model/{config['model_name']}.tflite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-20-2637122192.py\u001b[0m in \u001b[0;36mconvert_onnx_to_tflite\u001b[0;34m(onnx_model_path, output_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_rep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorflowRep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_unique_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupports_device\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon_supports_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/common/data_type.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'mapping' from 'onnx' (/usr/local/lib/python3.11/dist-packages/onnx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Step 4 (Optional): On Google Colab, sometimes the .tflite model isn't saved correctly\n",
        "# If so, run this cell to retry\n",
        "\n",
        "# Manually save to tflite as this doesn't work right in colab\n",
        "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "    # imports\n",
        "    import onnx\n",
        "    import logging\n",
        "    import tempfile\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Convert to tflite from onnx model\n",
        "    onnx_model = onnx.load(onnx_model_path)\n",
        "    tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "    return None\n",
        "\n",
        "convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9OyUW3ltOSs",
      "metadata": {
        "id": "f9OyUW3ltOSs"
      },
      "source": [
        "After the model finishes training, the auto training script will automatically convert it to ONNX and tflite versions, saving them as `my_custom_model/<model_name>.onnx/tflite` in the present working directory, where `<model_name>` is defined in the YAML training config file. Either version can be used as normal with `openwakeword`. I recommend testing them with the [`detect_from_microphone.py`](https://github.com/dscripka/openWakeWord/blob/main/examples/detect_from_microphone.py) example script to see how the model performs!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e44ea9b18624a90a3d35b8299c03c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eea618653c7f490c81a89cfb109a5e71",
              "IPY_MODEL_777b82999cf84c1aa34533796c1e711c",
              "IPY_MODEL_83fbfcff83e841459fce71d1846c94f9"
            ],
            "layout": "IPY_MODEL_1a7b9eb2956f439aa482d658c1ae3f97"
          }
        },
        "eea618653c7f490c81a89cfb109a5e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4347f16032694b79b0350064c34efdc1",
            "placeholder": "​",
            "style": "IPY_MODEL_06842584ba4a4180b80693d716cdbf0a",
            "value": "Downloading readme: 100%"
          }
        },
        "777b82999cf84c1aa34533796c1e711c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe70ea28273842248cea5a8ac4e00b33",
            "max": 936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b46c15956584717bd951ed6a2eb257b",
            "value": 936
          }
        },
        "83fbfcff83e841459fce71d1846c94f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb02d8407bf344b5a51017e50713c6e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2934db122e7944949d595b998033d777",
            "value": " 936/936 [00:00&lt;00:00, 112kB/s]"
          }
        },
        "1a7b9eb2956f439aa482d658c1ae3f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4347f16032694b79b0350064c34efdc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06842584ba4a4180b80693d716cdbf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe70ea28273842248cea5a8ac4e00b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b46c15956584717bd951ed6a2eb257b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb02d8407bf344b5a51017e50713c6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2934db122e7944949d595b998033d777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09b6b1b2b39482c9030c6e379111d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9832911bf32948f39af4bbf292200538",
              "IPY_MODEL_2fe5a9e352f94d9b9373bcf308f60e5a",
              "IPY_MODEL_90d50a7345ad42a6a3efa40aa19aeb9e"
            ],
            "layout": "IPY_MODEL_4f513eebdd9c4fb2b1d614fa3e74d575"
          }
        },
        "9832911bf32948f39af4bbf292200538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb17f68671c47ffb587213cb36f6391",
            "placeholder": "​",
            "style": "IPY_MODEL_e0783eb2a25f4cb0ac8ad77542029ec9",
            "value": "Resolving data files: 100%"
          }
        },
        "2fe5a9e352f94d9b9373bcf308f60e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693ba0e79b704b7b9e0d16643d72023d",
            "max": 270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c963783cb869420b95e32bdfe9660f75",
            "value": 270
          }
        },
        "90d50a7345ad42a6a3efa40aa19aeb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30871e05b7a940ecbf78a227804d4870",
            "placeholder": "​",
            "style": "IPY_MODEL_ffe3514faf5346f9ae0e40d03098f85a",
            "value": " 270/270 [00:00&lt;00:00, 34.90it/s]"
          }
        },
        "4f513eebdd9c4fb2b1d614fa3e74d575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb17f68671c47ffb587213cb36f6391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0783eb2a25f4cb0ac8ad77542029ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693ba0e79b704b7b9e0d16643d72023d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c963783cb869420b95e32bdfe9660f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30871e05b7a940ecbf78a227804d4870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe3514faf5346f9ae0e40d03098f85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}