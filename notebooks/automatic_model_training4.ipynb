{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stephanisk/notebook/blob/main/notebooks/automatic_model_training4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1eab0b3",
      "metadata": {
        "id": "c1eab0b3"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882058c5",
      "metadata": {
        "id": "882058c5"
      },
      "source": [
        "This notebook demonstrates how to train custom openWakeWord models using pre-defined datasets and an automated process for dataset generation and training. While not guaranteed to always produce the best performing model, the methods shown in this notebook often produce baseline models with releatively strong performance.\n",
        "\n",
        "Manual data preparation and model training (e.g., see the [training models](training_models.ipynb) notebook) remains an option for when full control over the model development process is needed.\n",
        "\n",
        "At a high level, the automatic training process takes advantages of several techniques to try and produce a good model, including:\n",
        "\n",
        "- Early-stopping and checkpoint averaging (similar to [stochastic weight averaging](https://arxiv.org/abs/1803.05407)) to search for the best models found during training, according to the validation data\n",
        "- Variable learning rates with cosine decay and multiple cycles\n",
        "- Adaptive batch construction to focus on only high-loss examples when the model begins to converge, combined with gradient accumulation to ensure that batch sizes are still large enough for stable training\n",
        "- Cycical weight schedules for negative examples to help the model reduce false-positive rates\n",
        "\n",
        "See the contents of the `train.py` file for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08d031b",
      "metadata": {
        "id": "e08d031b"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee78c37",
      "metadata": {
        "id": "aee78c37"
      },
      "source": [
        "To begin, we'll need to install the requirements for training custom models. In particular, a relatively recent version of Pytorch and custom fork of the [piper-sample-generator](https://github.com/dscripka/piper-sample-generator) library for generating synthetic examples for the custom model.\n",
        "\n",
        "**Important Note!** Currently, automated model training is only supported on linux systems due to the requirements of the text to speech library used for synthetic sample generation (Piper). It may be possible to use Piper on Windows/Mac systems, but that has not (yet) been tested."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Python version info: {sys.version_info}\")\n",
        "\n",
        "# Check if it's 3.11 or earlier\n",
        "if sys.version_info.major == 3 and sys.version_info.minor <= 11:\n",
        "    print(f\"✓ Python {sys.version_info.major}.{sys.version_info.minor} - Should work!\")\n",
        "else:\n",
        "    print(f\"✗ Python {sys.version_info.major}.{sys.version_info.minor} - Still too new\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJMMikhdoD5n",
        "outputId": "a256b06a-147f-4d37-e46b-09949b3a5791"
      },
      "id": "jJMMikhdoD5n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Python version info: sys.version_info(major=3, minor=11, micro=13, releaselevel='final', serial=0)\n",
            "✓ Python 3.11 - Should work!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b1227eb",
      "metadata": {
        "id": "4b1227eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7aef09-073b-4623-956c-85aab508c8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'piper-sample-generator' already exists and is not an empty directory.\n",
            "--2025-11-27 22:48:38--  https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A41%3A40Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A40%3A59Z&ske=2025-11-27T23%3A41%3A40Z&sks=b&skv=2018-11-09&sig=LUAKOS%2BBmcLAGI4qYFUq9u5lkZUiQSdS%2BK2D8r6biFo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NzMxOSwibmJmIjoxNzY0MjgzNzE5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.jQMIVn5VXmWl-0vCiGZgx-hvZQblCbdCEMdcSFwVxtA&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-27 22:48:39--  https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A41%3A40Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A40%3A59Z&ske=2025-11-27T23%3A41%3A40Z&sks=b&skv=2018-11-09&sig=LUAKOS%2BBmcLAGI4qYFUq9u5lkZUiQSdS%2BK2D8r6biFo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NzMxOSwibmJmIjoxNzY0MjgzNzE5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.jQMIVn5VXmWl-0vCiGZgx-hvZQblCbdCEMdcSFwVxtA&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204089915 (195M) [application/octet-stream]\n",
            "Saving to: ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’\n",
            "\n",
            "piper-sample-genera 100%[===================>] 194.63M   196MB/s    in 1.0s    \n",
            "\n",
            "2025-11-27 22:48:40 (196 MB/s) - ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’ saved [204089915/204089915]\n",
            "\n",
            "Requirement already satisfied: piper-phonemize in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "fatal: destination path 'openwakeword' already exists and is not an empty directory.\n",
            "Obtaining file:///content/openwakeword\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: onnxruntime<2,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.23.2)\n",
            "Requirement already satisfied: ai-edge-litert<3,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (2.0.3)\n",
            "Requirement already satisfied: speexdsp-ns<1,>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (0.1.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: scipy<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: backports.strenum in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (1.2.8)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert<3,>=2.0.2->openwakeword==0.6.0) (4.14.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (15.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (3.6.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.3.0)\n",
            "Building wheels for collected packages: openwakeword\n",
            "  Building editable for openwakeword (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openwakeword: filename=openwakeword-0.6.0-0.editable-py3-none-any.whl size=17481 sha256=18b83b502e75c1ca2f1333ff2505c958baf30119068d8f1aed1adab2cf16855c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-se6mv6am/wheels/0c/57/fb/ff0f65816c3a56a203bf97b5fba7bcc37a99e64ac8862bf609\n",
            "Successfully built openwakeword\n",
            "Installing collected packages: openwakeword\n",
            "  Attempting uninstall: openwakeword\n",
            "    Found existing installation: openwakeword 0.6.0\n",
            "    Uninstalling openwakeword-0.6.0:\n",
            "      Successfully uninstalled openwakeword-0.6.0\n",
            "Successfully installed openwakeword-0.6.0\n",
            "Requirement already satisfied: mutagen==1.47.0 in /usr/local/lib/python3.11/dist-packages (1.47.0)\n",
            "Requirement already satisfied: torchinfo==1.8.0 in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Collecting torchmetrics==1.2.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.2.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.2)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.15.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.2.0\n",
            "Collecting speechbrain==0.5.14\n",
            "  Using cached speechbrain-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hyperpyyaml (from speechbrain==0.5.14)\n",
            "  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (1.1.5)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.14)\n",
            "  Using cached ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.14)\n",
            "  Using cached ruamel_yaml_clib-0.2.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2025.7.14)\n",
            "Using cached speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.15 speechbrain-0.5.14\n",
            "Collecting audiomentations==0.33.0\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (2.0.2)\n",
            "Collecting librosa!=0.10.0,<0.11.0,>=0.8.0 (from audiomentations==0.33.0)\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (1.15.3)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.14.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2025.7.14)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: librosa, audiomentations\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "Successfully installed audiomentations-0.33.0 librosa-0.10.2.post1\n",
            "Collecting torch-audiomentations==0.11.0\n",
            "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations==0.11.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cu124)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations==0.11.0)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.14.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2025.7.14)\n",
            "Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Building wheels for collected packages: julius\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=fc29a6e9f550cb36919dbd25c9b748e897055d3c979d934c47f6ca092de8aaa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built julius\n",
            "Installing collected packages: primePy, julius, torch-pitch-shift, torch-audiomentations\n",
            "Successfully installed julius-0.2.7 primePy-1.3 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.5\n",
            "Collecting acoustics==0.2.6\n",
            "  Downloading acoustics-0.2.6.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (3.10.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.17.0)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (3.2.3)\n",
            "Building wheels for collected packages: acoustics\n",
            "  Building wheel for acoustics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.6-py3-none-any.whl size=68221 sha256=f17cfad111260d5ffe553c8a83f98a47034bb9c1bf020c8ef3fd2a38b410d9cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/f0/b5/30a5d47708560f77b9167961c7ce13ab1ecf6ac352a3c077c2\n",
            "Successfully built acoustics\n",
            "Installing collected packages: acoustics\n",
            "Successfully installed acoustics-0.2.6\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.8.1 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-cpu==2.8.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorflow_probability==0.16.0\n",
            "  Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (1.17.2)\n",
            "Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "Successfully installed tensorflow_probability-0.16.0\n",
            "Collecting onnx_tf==1.10.0\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting onnx>=1.10.2 (from onnx_tf==1.10.0)\n",
            "  Downloading onnx-1.19.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx_tf==1.10.0) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx_tf==1.10.0)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (4.14.1)\n",
            "Collecting ml_dtypes>=0.5.0 (from onnx>=1.10.2->onnx_tf==1.10.0)\n",
            "  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->onnx_tf==1.10.0) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx_tf==1.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, ml_dtypes, tensorflow-addons, onnx, onnx_tf\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.4\n",
            "    Uninstalling typeguard-4.4.4:\n",
            "      Successfully uninstalled typeguard-4.4.4\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml_dtypes-0.5.4 onnx-1.19.1 onnx_tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Collecting pronouncing==0.2.0\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing==0.2.0)\n",
            "  Downloading cmudict-1.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.23.0)\n",
            "Downloading cmudict-1.1.2-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6234 sha256=9ea2105bcd2676ac961f774b83279f5cc0578737dfccf6f4a325bfbb996c6a5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/81/fd/7edbf09827c7a7e2666e870b4c5c6b46c7ebd5defa399698bd\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.1.2 pronouncing-0.2.0\n",
            "Collecting datasets==2.14.6\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.70.15)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.6 fsspec-2023.10.0\n",
            "Collecting deep-phonemizer==0.0.19\n",
            "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (6.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.18.0)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2025.7.14)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (0.45.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer==0.0.19) (3.0.2)\n",
            "Building wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33272 sha256=22a26f0b2eb77a0127259df5157ea5a3988b5533f51eff920d9d6055a8ffb7c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/cc/01/1c74a1f4e6ba31a42bb82f4e3d852e2f23236fe3e5d589dcf3\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.19\n",
            "--2025-11-27 22:54:12--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A30%3A17Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A29%3A46Z&ske=2025-11-27T23%3A30%3A17Z&sks=b&skv=2018-11-09&sig=s%2FPN4aTaBnNghP1I5JntLa%2F%2FglqC1l2D3RtD6vc6LxQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MiwibmJmIjoxNzY0Mjg0MDUyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.WUDFg90YCp3LNQ4222DayzPsXHR2K1k0NjhKANlPxNI&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-27 22:54:12--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A30%3A17Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A29%3A46Z&ske=2025-11-27T23%3A30%3A17Z&sks=b&skv=2018-11-09&sig=s%2FPN4aTaBnNghP1I5JntLa%2F%2FglqC1l2D3RtD6vc6LxQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MiwibmJmIjoxNzY0Mjg0MDUyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.WUDFg90YCp3LNQ4222DayzPsXHR2K1k0NjhKANlPxNI&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1326578 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-11-27 22:54:12 (225 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
            "\n",
            "--2025-11-27 22:54:12--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A47Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A30%3A55Z&ske=2025-11-27T23%3A31%3A47Z&sks=b&skv=2018-11-09&sig=XsbvttwF7ma5r0I3hahpWydBhlEdH6FpQSKif70Ijmk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MywibmJmIjoxNzY0Mjg0MDUzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Sv_q3j4FA1VSQEQIVmKBsghtcfIAvaOQr9z9dNAHBY&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-27 22:54:13--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A47Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A30%3A55Z&ske=2025-11-27T23%3A31%3A47Z&sks=b&skv=2018-11-09&sig=XsbvttwF7ma5r0I3hahpWydBhlEdH6FpQSKif70Ijmk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MywibmJmIjoxNzY0Mjg0MDUzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Sv_q3j4FA1VSQEQIVmKBsghtcfIAvaOQr9z9dNAHBY&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330312 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-27 22:54:13 (127 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
            "\n",
            "--2025-11-27 22:54:13--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A43Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A30%3A56Z&ske=2025-11-27T23%3A31%3A43Z&sks=b&skv=2018-11-09&sig=HiuwWEr3ARxqtVGVUowJai9glCA5K%2BvTRESGDnsNxpo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MywibmJmIjoxNzY0Mjg0MDUzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Sv_q3j4FA1VSQEQIVmKBsghtcfIAvaOQr9z9dNAHBY&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-27 22:54:13--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A43Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A30%3A56Z&ske=2025-11-27T23%3A31%3A43Z&sks=b&skv=2018-11-09&sig=HiuwWEr3ARxqtVGVUowJai9glCA5K%2BvTRESGDnsNxpo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1MywibmJmIjoxNzY0Mjg0MDUzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Sv_q3j4FA1VSQEQIVmKBsghtcfIAvaOQr9z9dNAHBY&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1087958 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-11-27 22:54:14 (282 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
            "\n",
            "--2025-11-27 22:54:14--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A27Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A31%3A09Z&ske=2025-11-27T23%3A31%3A27Z&sks=b&skv=2018-11-09&sig=P2npaisqYHQWldqYFvOACkxPKUUr6DQDtiDSU6up2uQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1NCwibmJmIjoxNzY0Mjg0MDU0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Uk9AzEIXvqLwnK6L9F2UqpswXEjzJTy-GpqQvb-jHBA&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-27 22:54:14--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-27T23%3A31%3A27Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-27T22%3A31%3A09Z&ske=2025-11-27T23%3A31%3A27Z&sks=b&skv=2018-11-09&sig=P2npaisqYHQWldqYFvOACkxPKUUr6DQDtiDSU6up2uQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDI4NDM1NCwibmJmIjoxNzY0Mjg0MDU0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Uk9AzEIXvqLwnK6L9F2UqpswXEjzJTy-GpqQvb-jHBA&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092516 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-11-27 22:54:14 (130 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Environment setup\n",
        "\n",
        "# install piper-sample-generator (currently only supports linux systems)\n",
        "!git clone https://github.com/rhasspy/piper-sample-generator\n",
        "!wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "!pip install piper-phonemize\n",
        "!pip install webrtcvad\n",
        "\n",
        "# install openwakeword (full installation to support training)\n",
        "!git clone https://github.com/dscripka/openwakeword\n",
        "!pip install -e ./openwakeword\n",
        "!cd openwakeword\n",
        "\n",
        "# install other dependencies\n",
        "!pip install mutagen==1.47.0\n",
        "!pip install torchinfo==1.8.0\n",
        "!pip install torchmetrics==1.2.0\n",
        "!pip install speechbrain==0.5.14\n",
        "!pip install audiomentations==0.33.0\n",
        "!pip install torch-audiomentations==0.11.0\n",
        "!pip install acoustics==0.2.6\n",
        "!pip install tensorflow-cpu==2.8.1\n",
        "!pip install tensorflow_probability==0.16.0\n",
        "!pip install onnx_tf==1.10.0\n",
        "!pip install pronouncing==0.2.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install deep-phonemizer==0.0.19\n",
        "\n",
        "# Download required models (workaround for Colab)\n",
        "import os\n",
        "os.makedirs(\"./openwakeword/openwakeword/resources/models\")\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX 1: Install piper-tts (missing from environment setup)\n",
        "!pip install piper-tts --quiet\n",
        "\n",
        "# FIX 2: Patch train.py to add model parameter to generate_samples calls\n",
        "file_path = \"openwakeword/openwakeword/train.py\"\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Add model path variable after import\n",
        "if 'piper_model =' not in content:\n",
        "    content = content.replace(\n",
        "        'from generate_samples import generate_samples',\n",
        "        'from generate_samples import generate_samples\\n    piper_model = config.get(\"piper_sample_generator_model_path\", \"piper-sample-generator/models/en_US-libritts_r-medium.pt\")'\n",
        "    )\n",
        "\n",
        "# Fix all generate_samples calls\n",
        "content = content.replace(\n",
        "    '            generate_samples(\\n                text=config[\"target_phrase\"], max_samples=',\n",
        "    '            generate_samples(\\n                text=config[\"target_phrase\"], model=piper_model, max_samples='\n",
        ")\n",
        "content = content.replace(\n",
        "    '            generate_samples(text=adversarial_texts, max_samples=',\n",
        "    '            generate_samples(text=adversarial_texts, model=piper_model, max_samples='\n",
        ")\n",
        "content = content.replace(\n",
        "    '            generate_samples(text=config[\"target_phrase\"], max_samples=',\n",
        "    '            generate_samples(text=config[\"target_phrase\"], model=piper_model, max_samples='\n",
        ")\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Fixes applied!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DnKt6dR4V6C",
        "outputId": "2d347435-3c95-416d-f74a-b89a28bed8b4"
      },
      "id": "8DnKt6dR4V6C",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/13.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/13.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/13.8 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Fixes applied!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOWNLOAD MULTI-LANGUAGE MODELS (run after every restart)\n",
        "import os\n",
        "\n",
        "models_dir = \"piper-sample-generator/models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# These are the working Piper voices (ONNX format)\n",
        "models = {\n",
        "    \"de_DE\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/thorsten/medium/de_DE-thorsten-medium.onnx\",\n",
        "    \"de_DE_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/thorsten/medium/de_DE-thorsten-medium.onnx.json\",\n",
        "\n",
        "    \"es_ES\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/es/es_ES/davefx/medium/es_ES-davefx-medium.onnx\",\n",
        "    \"es_ES_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/es/es_ES/davefx/medium/es_ES-davefx-medium.onnx.json\",\n",
        "\n",
        "    \"fr_FR\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx\",\n",
        "    \"fr_FR_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx.json\",\n",
        "\n",
        "    \"pt_BR\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx\",\n",
        "    \"pt_BR_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx.json\",\n",
        "\n",
        "    \"ru_RU\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx\",\n",
        "    \"ru_RU_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx.json\",\n",
        "\n",
        "    \"zh_CN\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx\",\n",
        "    \"zh_CN_json\": \"https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx.json\",\n",
        "}\n",
        "\n",
        "print(\"Downloading multi-language Piper models...\")\n",
        "print(\"(This takes ~2 minutes)\")\n",
        "\n",
        "for name, url in models.items():\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    output_path = f\"{models_dir}/{filename}\"\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"✓ {filename} (already exists)\")\n",
        "    else:\n",
        "        print(f\"⬇ Downloading {filename}...\")\n",
        "        !wget -q -O {output_path} {url}\n",
        "        if os.path.exists(output_path) and os.path.getsize(output_path) > 1000:\n",
        "            print(f\"  ✓ Done ({os.path.getsize(output_path)/(1024*1024):.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"  ❌ Failed!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Model download complete! Verifying...\")\n",
        "!ls -lh {models_dir}/*.onnx 2>/dev/null | awk '{{print $9, $5}}'\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "wuvdkjDpj1HE",
        "outputId": "439fa253-82cb-4407-ecbb-68e10b7c9dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wuvdkjDpj1HE",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading multi-language Piper models...\n",
            "(This takes ~2 minutes)\n",
            "⬇ Downloading de_DE-thorsten-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading de_DE-thorsten-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading es_ES-davefx-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading es_ES-davefx-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading fr_FR-siwis-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading fr_FR-siwis-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading pt_BR-faber-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading pt_BR-faber-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading ru_RU-dmitri-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading ru_RU-dmitri-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "⬇ Downloading zh_CN-huayan-medium.onnx...\n",
            "  ✓ Done (60.3 MB)\n",
            "⬇ Downloading zh_CN-huayan-medium.onnx.json...\n",
            "  ✓ Done (0.0 MB)\n",
            "\n",
            "============================================================\n",
            "Model download complete! Verifying...\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "9 5\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smDTauKf6IrQ",
        "outputId": "84aa39f3-188b-4407-cc92-092bf39a3b18"
      },
      "id": "smDTauKf6IrQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d4c1056e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:42:01.183840Z",
          "start_time": "2023-09-04T13:41:59.752153Z"
        },
        "id": "d4c1056e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import yaml\n",
        "import datasets\n",
        "import scipy\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d7a05a",
      "metadata": {
        "id": "e9d7a05a"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52f75cc",
      "metadata": {
        "id": "c52f75cc"
      },
      "source": [
        "When training new openWakeWord models using the automated procedure, four specific types of data are required:\n",
        "\n",
        "1) Synthetic examples of the target word/phrase generated with text-to-speech models\n",
        "\n",
        "2) Synthetic examples of adversarial words/phrases generated with text-to-speech models\n",
        "\n",
        "3) Room impulse reponses and noise/background audio data to augment the synthetic examples and make them more realistic\n",
        "\n",
        "4) Generic \"negative\" audio data that is very unlikely to contain examples of the target word/phrase in the context where the model should detect it. This data can be the original audio data, or precomputed openWakeWord features ready for model training.\n",
        "\n",
        "5) Validation data to use for early-stopping when training the model.\n",
        "\n",
        "For the purposes of this notebook, all five of these sources will either be generated manually or can be obtained from HuggingFace thanks to their excellent `datasets` library and extremely generous hosting policy. Also note that while only a portion of some datasets are downloaded, for the best possible performance it is recommended to download the entire dataset and keep a local copy for future training runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d25a93b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T01:07:17.746749Z",
          "start_time": "2023-09-04T01:07:17.740846Z"
        },
        "id": "d25a93b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "3de46a27878e4911ae5ae0c03b7e66a6",
            "5fc98fbb222e4f1b84093527c9d8eef5",
            "a910af17255b42a4bb0f4511aa00cff4",
            "855f2a7c57c2423e94939390dfdd981d",
            "abcfddc9de4a40739ee4ea8e8918692a",
            "8a0d7910b28c4fd99087dfe540be6ac3",
            "7b9af137ebba4ba4bfcaf76f7cfd46e4",
            "944cf785ae5b40e2ad567079ff5d1de8",
            "edef5e08fb1646f38b46504ed658e9fd",
            "06ee0698619b42bc8e3b323ec478828f",
            "aef9cf123a8742cc95efd4f216622d23",
            "3730a67c44654f468fa3b0e1337f2847",
            "88dbb40ad3174d9190f9da40d2d7f806",
            "619c8a7514a84ade9adc17bd96497af1",
            "f744748204fd4807b4e50709651051ed",
            "8a0febc97315407dac6fe5be8bbf79c1",
            "fc7d3de401c342be86277311437ae623",
            "fba5469d2d8b427d9cd5fc7f8289d57e",
            "550093ec0aa744d98a59da0f146871f0",
            "00a948b7213a4e53b38ce71b13201df7",
            "a914be22ca614f978be37e05f2223d08",
            "948d416c389846ecbd3f746cdc06913f"
          ]
        },
        "outputId": "ab2e92d4-6ae7-4bfb-861d-435479c4e7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/936 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3de46a27878e4911ae5ae0c03b7e66a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "HTTP Error 429 thrown while requesting GET https://huggingface.co/api/datasets/davidscripka/MIT_environmental_impulse_responses/tree/b824a1ef2821f112fda0b9cb26e4278c62b425bb/16khz?expand=true&recursive=true&limit=50&cursor=ZXlKbWFXeGxYMjVoYldVaU9pSXhObXRvZWk5b01UQXdYME5zWVhOemNtOXZiVjh5ZEhoMGN5NTNZWFlpTENKMGNtVmxYMjlwWkNJNkltWmtOelV3WVdZME1qRmtOekUxTnpSak9XTTFOamcwTURSaE56VTBaalV4TkRVek5EVTBNVEFpZlE9PToxMDA%3D\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 429 thrown while requesting GET https://huggingface.co/api/datasets/davidscripka/MIT_environmental_impulse_responses/tree/b824a1ef2821f112fda0b9cb26e4278c62b425bb/16khz?expand=true&recursive=true&limit=50&cursor=ZXlKbWFXeGxYMjVoYldVaU9pSXhObXRvZWk5b01UQXdYME5zWVhOemNtOXZiVjh5ZEhoMGN5NTNZWFlpTENKMGNtVmxYMjlwWkNJNkltWmtOelV3WVdZME1qRmtOekUxTnpSak9XTTFOamcwTURSaE56VTBaalV4TkRVek5EVTBNVEFpZlE9PToxMDA%3D\n",
            "Retrying in 1s [Retry 1/20].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/20].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/270 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3730a67c44654f468fa3b0e1337f2847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "270it [01:54,  2.36it/s]\n"
          ]
        }
      ],
      "source": [
        "# Download room impulse responses collected by MIT\n",
        "# https://mcdermottlab.mit.edu/Reverb/IR_Survey.html\n",
        "\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
        "\n",
        "# Save clips to 16-bit PCM wav files\n",
        "for row in tqdm(rir_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1]\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Check if we have the big files in Drive already\n",
        "drive_backup = '/content/drive/MyDrive/openWakeWord_backup'\n",
        "\n",
        "if os.path.exists(f'{drive_backup}/openwakeword_features_ACAV100M_2000_hrs_16bit.npy'):\n",
        "    print(\"✓ Found backup files in Drive! Copying to workspace...\")\n",
        "\n",
        "    # Copy from Drive instead of downloading\n",
        "    if not os.path.exists('openwakeword_features_ACAV100M_2000_hrs_16bit.npy'):\n",
        "        shutil.copy(f'{drive_backup}/openwakeword_features_ACAV100M_2000_hrs_16bit.npy', '.')\n",
        "    if not os.path.exists('validation_set_features.npy'):\n",
        "        shutil.copy(f'{drive_backup}/validation_set_features.npy', '.')\n",
        "\n",
        "    print(\"✓ Files restored from Drive!\")\n",
        "else:\n",
        "    print(\"No backup found - will download and then backup to Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqBsF5A46sX-",
        "outputId": "060f9528-a619-404e-e0da-b09bd44361e5"
      },
      "id": "FqBsF5A46sX-",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Found backup files in Drive! Copying to workspace...\n",
            "✓ Files restored from Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2c0e178b",
      "metadata": {
        "id": "2c0e178b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "ec8d55bd7c834e49b5d78c43fb8c78e7",
            "9035847498794337bfd4ffcdfe0cb9e5",
            "c8c0d4f7942c428ba484e58573869aed",
            "c3103c02273a4b409add5c641c8f6b1d",
            "8360062307224683ab988bd3f5e28a5a",
            "c0409fec5029400892c95aff59f05f3e",
            "892dbd13b15c4a1781c7fd2b11325dc1",
            "e0b1b7c51c7a4326ab3101578bacd8d3",
            "050102253a714efcac91be62af4908ef",
            "b4353db2b1ec420891c06eb931bfc0d3",
            "864236d857fd4c20b847b6fe2bba91fd",
            "86ee7c07a992446da4bd247bf989518d",
            "0ddb49d4f17d4906a2b83a7f486afc0f",
            "9b9fa893cefc49a197a9e76383bc02d7",
            "183f52ec7357466b98e4d8b984af5eb8",
            "10a20fc4bf1243d7ac9530e6dae38943",
            "716f6b42e99d48dab530ec7cea18a211",
            "fc93db92ccca4c95b483eb76dde4f2ea",
            "a93fe5693d1847e88d4607d768f2d72e",
            "1b95806227f34bbcb5a4d30efa19f0d5",
            "24dde86654c24740964fa1c98afcc750",
            "a253ac338dae479fa1c040c78d55f871"
          ]
        },
        "outputId": "ec1cecc2-7eee-4fe0-85ad-e2787a9abbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-27 23:01:19--  https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/bal_train09.tar\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.97, 13.35.202.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-11-27 23:01:19 ERROR 404: Not Found.\n",
            "\n",
            "tar: This does not look like a tar archive\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec8d55bd7c834e49b5d78c43fb8c78e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86ee7c07a992446da4bd247bf989518d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 119/120 [00:37<00:00,  3.18it/s]\n"
          ]
        }
      ],
      "source": [
        "## Download noise and background audio\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "fname = \"bal_train09.tar\"\n",
        "out_dir = f\"audioset/{fname}\"\n",
        "link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
        "!wget -O {out_dir} {link}\n",
        "!cd audioset && tar -xvf bal_train09.tar\n",
        "\n",
        "output_dir = \"./audioset_16k\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "# Convert audioset files to 16khz sample rate\n",
        "audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "for row in tqdm(audioset_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset (https://github.com/mdeff/fma)\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "n_hours = 1  # use only 1 hour of clips for this example notebook, recommend increasing for full-scale training\n",
        "for i in tqdm(range(n_hours*3600//30)):  # this works because the FMA dataset is all 30 second clips\n",
        "    row = next(fma_dataset)\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "    i += 1\n",
        "    if i == n_hours*3600//30:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01ec467",
      "metadata": {
        "id": "d01ec467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9bd725-9917-4803-ba1b-a012efc692ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-27 01:30:30--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.40, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013031Z&X-Amz-Expires=3600&X-Amz-Signature=a61fbd21c6761a95cb32ca00543983b2a02687faa53653ba2b3ec4bfde7e0cb8&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1764210631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=Bk4iFZbhEWkFJom4Fb7NIA2nhdojXzD89F0cB9QesaYVyfpdg2uGhK3plGfxllLLqu%7EUtrrxRqUeuW8c7cm8XwjvORYT9FTODFjgG0%7E2gmSLd5jeG4TW%7EpXIkox7dB2c%7EgBM8v5wSz99-eyVBl7yVAwawIwnQo-1Vcio13M6tbf5DIlanFCs9Iz0wHTXRDC3Y4Iqx60I4p%7Ee-4-WEs8KjFRwoAP2UqD%7EXFKztxY%7Ef%7EV8Z1JACkBB365ZcVo8mOT5iP9lpwCy3VhZ57xNDRAZLJpgtR8aWYpxHNgFD4UYtbnn93eQsuQfOQx-ELX-V6aBgOSlinbvM%7En7edArMzPCOw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-27 01:30:31--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013031Z&X-Amz-Expires=3600&X-Amz-Signature=a61fbd21c6761a95cb32ca00543983b2a02687faa53653ba2b3ec4bfde7e0cb8&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1764210631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=Bk4iFZbhEWkFJom4Fb7NIA2nhdojXzD89F0cB9QesaYVyfpdg2uGhK3plGfxllLLqu%7EUtrrxRqUeuW8c7cm8XwjvORYT9FTODFjgG0%7E2gmSLd5jeG4TW%7EpXIkox7dB2c%7EgBM8v5wSz99-eyVBl7yVAwawIwnQo-1Vcio13M6tbf5DIlanFCs9Iz0wHTXRDC3Y4Iqx60I4p%7Ee-4-WEs8KjFRwoAP2UqD%7EXFKztxY%7Ef%7EV8Z1JACkBB365ZcVo8mOT5iP9lpwCy3VhZ57xNDRAZLJpgtR8aWYpxHNgFD4UYtbnn93eQsuQfOQx-ELX-V6aBgOSlinbvM%7En7edArMzPCOw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 108.157.254.62, 108.157.254.55, 108.157.254.25, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|108.157.254.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17280000128 (16G)\n",
            "Saving to: ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’\n",
            "\n",
            "openwakeword_featur 100%[===================>]  16.09G   236MB/s    in 74s     \n",
            "\n",
            "2025-11-27 01:31:45 (222 MB/s) - ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’ saved [17280000128/17280000128]\n",
            "\n",
            "--2025-11-27 01:31:45--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.97, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013145Z&X-Amz-Expires=3600&X-Amz-Signature=d8d722f343df46285962dd4b055e50279904cc3a27fad427d452d45b56e69c0d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1764210705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=Rg8048vBpRbux-lmLimkk4epLrA66Qc8Fp0Romf57KbPYXD46kx80%7ErKpgL-K0ace1nYPTMOiTEdS4kEb-lBlzdVVmTEze%7EKfHgijcoVR3y6jrv8wtvLywvv6kfDrYcI91x4yVIxwtmaLcy1z2CRFtZMDotp6ceqMztmC%7E8O529tU5rV9fNrk3iJmJCP4p8DE9CnNqKKGjbywjVH%7ECwYovIgq9CkyCSu6wpA2qjlrqJiLxKlNobDpWDxfMyOBt8vMgZ6Dx-ZS2aHg1FiV8ez0yCM7OENxVNJqKo4BaLy6Y4RTDJvesKwwO9nFKtXz1gJSDZnpqvwvJhBv67Q7z7ARA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-27 01:31:45--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251127T013145Z&X-Amz-Expires=3600&X-Amz-Signature=d8d722f343df46285962dd4b055e50279904cc3a27fad427d452d45b56e69c0d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1764210705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDIxMDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=Rg8048vBpRbux-lmLimkk4epLrA66Qc8Fp0Romf57KbPYXD46kx80%7ErKpgL-K0ace1nYPTMOiTEdS4kEb-lBlzdVVmTEze%7EKfHgijcoVR3y6jrv8wtvLywvv6kfDrYcI91x4yVIxwtmaLcy1z2CRFtZMDotp6ceqMztmC%7E8O529tU5rV9fNrk3iJmJCP4p8DE9CnNqKKGjbywjVH%7ECwYovIgq9CkyCSu6wpA2qjlrqJiLxKlNobDpWDxfMyOBt8vMgZ6Dx-ZS2aHg1FiV8ez0yCM7OENxVNJqKo4BaLy6Y4RTDJvesKwwO9nFKtXz1gJSDZnpqvwvJhBv67Q7z7ARA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 108.157.254.115, 108.157.254.55, 108.157.254.62, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|108.157.254.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184836608 (176M)\n",
            "Saving to: ‘validation_set_features.npy’\n",
            "\n",
            "validation_set_feat 100%[===================>] 176.27M   325MB/s    in 0.5s    \n",
            "\n",
            "2025-11-27 01:31:46 (325 MB/s) - ‘validation_set_features.npy’ saved [184836608/184836608]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download pre-computed openWakeWord features for training and validation\n",
        "\n",
        "# training set (~2,000 hours from the ACAV100M Dataset)\n",
        "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "\n",
        "# validation set for false positive rate estimation (~11 hours)\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create backup directory in Drive\n",
        "drive_backup = '/content/drive/MyDrive/openWakeWord_backup'\n",
        "os.makedirs(drive_backup, exist_ok=True)\n",
        "\n",
        "# Copy the big files to Drive (only if not already there)\n",
        "files_to_backup = [\n",
        "    'openwakeword_features_ACAV100M_2000_hrs_16bit.npy',\n",
        "    'validation_set_features.npy'\n",
        "]\n",
        "\n",
        "for filename in files_to_backup:\n",
        "    if os.path.exists(filename):\n",
        "        drive_path = f'{drive_backup}/{filename}'\n",
        "        if not os.path.exists(drive_path):\n",
        "            print(f\"Backing up {filename} to Drive... (takes 2-3 min)\")\n",
        "            shutil.copy(filename, drive_path)\n",
        "            print(f\"✓ {filename} backed up!\")\n",
        "        else:\n",
        "            print(f\"✓ {filename} already in Drive\")\n",
        "\n",
        "print(\"\\n✓ All files backed up to Google Drive!\")\n",
        "print(\"Next time, run Cell 2 above to restore instead of re-downloading!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcxGoeIJ60GN",
        "outputId": "e05eaf50-cee6-4168-a499-41fd73726c02"
      },
      "id": "KcxGoeIJ60GN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backing up openwakeword_features_ACAV100M_2000_hrs_16bit.npy to Drive... (takes 2-3 min)\n",
            "✓ openwakeword_features_ACAV100M_2000_hrs_16bit.npy backed up!\n",
            "Backing up validation_set_features.npy to Drive... (takes 2-3 min)\n",
            "✓ validation_set_features.npy backed up!\n",
            "\n",
            "✓ All files backed up to Google Drive!\n",
            "Next time, run Cell 2 above to restore instead of re-downloading!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe82647",
      "metadata": {
        "id": "cfe82647"
      },
      "source": [
        "# Define Training Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e71329",
      "metadata": {
        "id": "b2e71329"
      },
      "source": [
        "For automated model training openWakeWord uses a specially designed training script and a [YAML](https://yaml.org/) configuration file that defines all of the information required for training a new wake word/phrase detection model.\n",
        "\n",
        "It is strongly recommended that you review [the example config file](../examples/custom_model.yml), as each value is fully documented there. For the purposes of this notebook, we'll read in the YAML file to modify certain configuration parameters before saving a new YAML file for training our example model. Specifically:\n",
        "\n",
        "- We'll train a detection model for the phrase \"hey sebastian\"\n",
        "- We'll only generate 5,000 positive and negative examples (to save on time for this example)\n",
        "- We'll only generate 1,000 validation positive and negative examples for early stopping (again to save time)\n",
        "- The model will only be trained for 10,000 steps (larger datasets will benefit from longer training)\n",
        "- We'll reduce the target metrics to account for the small dataset size and limited training.\n",
        "\n",
        "On the topic of target metrics, there are *not* specific guidelines about what these metrics should be in practice, and you will need to conduct testing in your target deployment environment to establish good thresholds. However, from very limited testing the default values in the config file (accuracy >= 0.7, recall >= 0.5, false-positive rate <= 0.2 per hour) seem to produce models with reasonable performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fb0b6e4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T18:11:33.893397Z",
          "start_time": "2023-09-04T18:11:33.878938Z"
        },
        "id": "fb0b6e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b0e68a-587f-4ae5-9aca-59d592db4ba8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'my_model',\n",
              " 'target_phrase': ['hey jarvis'],\n",
              " 'custom_negative_phrases': [],\n",
              " 'n_samples': 10000,\n",
              " 'n_samples_val': 2000,\n",
              " 'tts_batch_size': 50,\n",
              " 'augmentation_batch_size': 16,\n",
              " 'piper_sample_generator_path': './piper-sample-generator',\n",
              " 'output_dir': './my_custom_model',\n",
              " 'rir_paths': ['./mit_rirs'],\n",
              " 'background_paths': ['./background_clips'],\n",
              " 'background_paths_duplication_rate': [1],\n",
              " 'false_positive_validation_data_path': './validation_set_features.npy',\n",
              " 'augmentation_rounds': 1,\n",
              " 'feature_data_files': {'ACAV100M_sample': './openwakeword_features_ACAV100M_2000_hrs_16bit.npy'},\n",
              " 'batch_n_per_class': {'ACAV100M_sample': 1024,\n",
              "  'adversarial_negative': 50,\n",
              "  'positive': 50},\n",
              " 'model_type': 'dnn',\n",
              " 'layer_size': 32,\n",
              " 'steps': 50000,\n",
              " 'max_negative_weight': 1500,\n",
              " 'target_false_positives_per_hour': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load default YAML config file for training\n",
        "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "482cf2d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:07:00.859210Z",
          "start_time": "2023-09-04T15:07:00.841472Z"
        },
        "id": "482cf2d0"
      },
      "outputs": [],
      "source": [
        "# Modify values in the config and save a new version\n",
        "\n",
        "config[\"target_phrase\"] = [\"Hello James\"]\n",
        "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
        "\n",
        "# INCREASED for multi-language training\n",
        "config[\"n_samples\"] = 4500  # 500 per language × 9 languages\n",
        "config[\"n_samples_val\"] = 4500\n",
        "\n",
        "config[\"steps\"] = 20000  # More steps for better multi-language learning\n",
        "config[\"target_accuracy\"] = 0.6\n",
        "config[\"target_recall\"] = 0.25\n",
        "\n",
        "config[\"background_paths\"] = ['./audioset_16k', './fma']\n",
        "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "with open('my_model.yaml', 'w') as file:\n",
        "    documents = yaml.dump(config, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6b2ab0",
      "metadata": {
        "id": "aa6b2ab0"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51202c0",
      "metadata": {
        "id": "a51202c0"
      },
      "source": [
        "With the data downloaded and training configuration set, we can now start training the model. We'll do this in parts to better illustrate the sequence, but you can also execute every step at once for a fully automated process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PRE-FLIGHT CHECK: Test piper and verify all models exist\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 PRE-FLIGHT CHECKS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Check piper binary\n",
        "print(\"\\n1️⃣ Testing piper binary...\")\n",
        "piper_path = \"/usr/local/bin/piper\"\n",
        "if not os.path.exists(piper_path):\n",
        "    print(f\"❌ Piper binary not found at {piper_path}\")\n",
        "    print(\"Run FIX 1 cell to install piper!\")\n",
        "else:\n",
        "    print(f\"✓ Piper binary exists\")\n",
        "\n",
        "    # Test with a simple model\n",
        "    test_model = \"piper-sample-generator/models/en_US-libritts_r-medium.onnx\"\n",
        "    if os.path.exists(test_model):\n",
        "        test_file = \"/tmp/piper_test.wav\"\n",
        "        cmd = f'echo \"Hello James\" | {piper_path} --model {test_model} --output_file {test_file}'\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0 and os.path.exists(test_file) and os.path.getsize(test_file) > 100:\n",
        "            size = os.path.getsize(test_file)\n",
        "            print(f\"✓ Piper works! Test file: {size} bytes\")\n",
        "            os.remove(test_file)  # cleanup\n",
        "        else:\n",
        "            print(f\"❌ PIPER FAILED!\")\n",
        "            print(f\"   Return code: {result.returncode}\")\n",
        "            print(f\"   STDERR: {result.stderr[:300]}\")\n",
        "            print(f\"   STDOUT: {result.stdout[:300]}\")\n",
        "            print(\"\\n⚠️ Try installing onnxruntime:\")\n",
        "            print(\"   !pip install onnxruntime\")\n",
        "    else:\n",
        "        print(f\"⚠️ Test model not found: {test_model}\")\n",
        "\n",
        "# 2. Check all language models\n",
        "print(\"\\n2️⃣ Checking language models...\")\n",
        "languages = {\n",
        "    \"en_US\": (\"piper-sample-generator/models/en_US-libritts_r-medium.pt\", \"pt\"),\n",
        "    \"de_DE\": (\"piper-sample-generator/models/de_DE-thorsten-medium.onnx\", \"onnx\"),\n",
        "    \"es_ES\": (\"piper-sample-generator/models/es_ES-davefx-medium.onnx\", \"onnx\"),\n",
        "    \"fr_FR\": (\"piper-sample-generator/models/fr_FR-siwis-medium.onnx\", \"onnx\"),\n",
        "    \"pt_BR\": (\"piper-sample-generator/models/pt_BR-faber-medium.onnx\", \"onnx\"),\n",
        "    \"ru_RU\": (\"piper-sample-generator/models/ru_RU-dmitri-medium.onnx\", \"onnx\"),\n",
        "    \"zh_CN\": (\"piper-sample-generator/models/zh_CN-huayan-medium.onnx\", \"onnx\")\n",
        "}\n",
        "\n",
        "found_models = []\n",
        "missing_models = []\n",
        "\n",
        "for lang, (model_path, model_type) in languages.items():\n",
        "    if os.path.exists(model_path):\n",
        "        size_mb = os.path.getsize(model_path) / (1024*1024)\n",
        "        print(f\"✓ {lang:8} ({model_type}): {size_mb:.1f} MB\")\n",
        "        found_models.append(lang)\n",
        "    else:\n",
        "        print(f\"❌ {lang:8}: NOT FOUND at {model_path}\")\n",
        "        missing_models.append(lang)\n",
        "\n",
        "# 3. Check what models ARE available\n",
        "if missing_models:\n",
        "    print(f\"\\n⚠️ Missing {len(missing_models)} models: {missing_models}\")\n",
        "    print(\"\\nAvailable models in directory:\")\n",
        "    !ls -lh piper-sample-generator/models/*.{pt,onnx} 2>/dev/null | awk '{print $9, $5}'\n",
        "\n",
        "# 4. Check Drive backup status\n",
        "print(\"\\n3️⃣ Checking Drive backup status...\")\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "if os.path.exists(backup_base):\n",
        "    completed = [d for d in os.listdir(backup_base)\n",
        "                 if os.path.isdir(f\"{backup_base}/{d}\")\n",
        "                 and len(os.listdir(f\"{backup_base}/{d}\")) > 0]\n",
        "\n",
        "    if completed:\n",
        "        print(f\"✓ Already completed: {completed}\")\n",
        "        for lang in completed:\n",
        "            file_count = len(os.listdir(f\"{backup_base}/{lang}\"))\n",
        "            print(f\"   {lang}: {file_count} files\")\n",
        "    else:\n",
        "        print(\"  No languages completed yet\")\n",
        "else:\n",
        "    print(\"  Backup directory doesn't exist yet (will be created)\")\n",
        "\n",
        "# 5. Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✓ Models ready: {len(found_models)}/{len(languages)}\")\n",
        "print(f\"  {found_models}\")\n",
        "if missing_models:\n",
        "    print(f\"❌ Models missing: {len(missing_models)}\")\n",
        "    print(f\"  {missing_models}\")\n",
        "    print(\"\\n⚠️ Generation will SKIP missing models\")\n",
        "else:\n",
        "    print(\"✓ ALL MODELS READY!\")\n",
        "\n",
        "print(\"\\nIf piper test failed, run: !pip install onnxruntime\")\n",
        "print(\"Then re-run this cell to verify.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "u-kKYV95g9B0",
        "outputId": "7f59fb75-6a65-4448-c614-eabdeb550871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "u-kKYV95g9B0",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🔍 PRE-FLIGHT CHECKS\n",
            "============================================================\n",
            "\n",
            "1️⃣ Testing piper binary...\n",
            "✓ Piper binary exists\n",
            "⚠️ Test model not found: piper-sample-generator/models/en_US-libritts_r-medium.onnx\n",
            "\n",
            "2️⃣ Checking language models...\n",
            "✓ en_US    (pt): 194.6 MB\n",
            "✓ de_DE    (onnx): 60.3 MB\n",
            "✓ es_ES    (onnx): 60.3 MB\n",
            "✓ fr_FR    (onnx): 60.3 MB\n",
            "✓ pt_BR    (onnx): 60.3 MB\n",
            "✓ ru_RU    (onnx): 60.3 MB\n",
            "✓ zh_CN    (onnx): 60.3 MB\n",
            "\n",
            "3️⃣ Checking Drive backup status...\n",
            "✓ Already completed: ['en_US', 'de_DE', 'es_ES']\n",
            "   en_US: 2850 files\n",
            "   de_DE: 1610 files\n",
            "   es_ES: 1300 files\n",
            "\n",
            "============================================================\n",
            "📊 SUMMARY\n",
            "============================================================\n",
            "✓ Models ready: 7/7\n",
            "  ['en_US', 'de_DE', 'es_ES', 'fr_FR', 'pt_BR', 'ru_RU', 'zh_CN']\n",
            "✓ ALL MODELS READY!\n",
            "\n",
            "If piper test failed, run: !pip install onnxruntime\n",
            "Then re-run this cell to verify.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f01531fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:50:08.803326Z",
          "start_time": "2023-09-04T13:50:06.790241Z"
        },
        "id": "f01531fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b5fe92-83a6-491d-9044-9a08b29769be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Already completed languages: ['en_US', 'de_DE', 'es_ES', '.ipynb_checkpoints']\n",
            "\n",
            "✓ en_US already backed up, skipping...\n",
            "\n",
            "✓ de_DE already backed up, skipping...\n",
            "\n",
            "✓ es_ES already backed up, skipping...\n",
            "\n",
            "============================================================\n",
            "🎤 fr_FR: Generating 650 samples...\n",
            "============================================================\n",
            "   Training: 100/650 (100 successful)\n",
            "   Training: 200/650 (200 successful)\n",
            "   Training: 300/650 (300 successful)\n",
            "   Training: 400/650 (400 successful)\n",
            "   Training: 500/650 (500 successful)\n",
            "   Training: 600/650 (600 successful)\n",
            "   Validation: 100/650\n",
            "   Validation: 200/650\n",
            "   Validation: 300/650\n",
            "   Validation: 400/650\n",
            "   Validation: 500/650\n",
            "   Validation: 600/650\n",
            "\n",
            "   💾 Backing up fr_FR to Drive...\n",
            "   💾 BACKED UP 1300 files to Drive!\n",
            "   ✓ fr_FR COMPLETE AND SAVED!\n",
            "\n",
            "============================================================\n",
            "🎤 pt_BR: Generating 650 samples...\n",
            "============================================================\n",
            "   Training: 100/650 (100 successful)\n",
            "   Training: 200/650 (200 successful)\n",
            "   Training: 300/650 (300 successful)\n",
            "   Training: 400/650 (400 successful)\n",
            "   Training: 500/650 (500 successful)\n",
            "   Training: 600/650 (600 successful)\n",
            "   Validation: 100/650\n",
            "   Validation: 200/650\n",
            "   Validation: 300/650\n",
            "   Validation: 400/650\n",
            "   Validation: 500/650\n",
            "   Validation: 600/650\n",
            "\n",
            "   💾 Backing up pt_BR to Drive...\n",
            "   💾 BACKED UP 1300 files to Drive!\n",
            "   ✓ pt_BR COMPLETE AND SAVED!\n",
            "\n",
            "============================================================\n",
            "🎤 ru_RU: Generating 650 samples...\n",
            "============================================================\n",
            "   Training: 100/650 (100 successful)\n",
            "   Training: 200/650 (200 successful)\n",
            "   Training: 300/650 (300 successful)\n",
            "   Training: 400/650 (400 successful)\n",
            "   Training: 500/650 (500 successful)\n",
            "   Training: 600/650 (600 successful)\n",
            "   Validation: 100/650\n",
            "   Validation: 200/650\n",
            "   Validation: 300/650\n",
            "   Validation: 400/650\n",
            "   Validation: 500/650\n",
            "   Validation: 600/650\n",
            "\n",
            "   💾 Backing up ru_RU to Drive...\n",
            "   💾 BACKED UP 1300 files to Drive!\n",
            "   ✓ ru_RU COMPLETE AND SAVED!\n",
            "\n",
            "============================================================\n",
            "🎤 zh_CN: Generating 650 samples...\n",
            "============================================================\n",
            "   Training: 100/650 (100 successful)\n",
            "   Training: 200/650 (200 successful)\n",
            "   Training: 300/650 (300 successful)\n",
            "   Training: 400/650 (400 successful)\n",
            "   Training: 500/650 (500 successful)\n",
            "   Training: 600/650 (600 successful)\n",
            "   Validation: 100/650\n",
            "   Validation: 200/650\n",
            "   Validation: 300/650\n",
            "   Validation: 400/650\n",
            "   Validation: 500/650\n",
            "   Validation: 600/650\n",
            "\n",
            "   💾 Backing up zh_CN to Drive...\n",
            "   💾 BACKED UP 1300 files to Drive!\n",
            "   ✓ zh_CN COMPLETE AND SAVED!\n",
            "\n",
            "============================================================\n",
            "✓ ALL LANGUAGES COMPLETE!\n",
            "============================================================\n",
            "Total samples: 2600\n"
          ]
        }
      ],
      "source": [
        "# SAFE Multi-language generation with auto-backup after EACH language\n",
        "import os, uuid, subprocess, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount drive first\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Drive already mounted\")\n",
        "\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "os.makedirs(backup_base, exist_ok=True)\n",
        "\n",
        "languages = {\n",
        "    \"en_US\": (\"piper-sample-generator/models/en_US-libritts_r-medium.pt\", \"pt\"),\n",
        "    \"de_DE\": (\"piper-sample-generator/models/de_DE-thorsten-medium.onnx\", \"onnx\"),\n",
        "    \"es_ES\": (\"piper-sample-generator/models/es_ES-davefx-medium.onnx\", \"onnx\"),\n",
        "    \"fr_FR\": (\"piper-sample-generator/models/fr_FR-siwis-medium.onnx\", \"onnx\"),\n",
        "    \"pt_BR\": (\"piper-sample-generator/models/pt_BR-faber-medium.onnx\", \"onnx\"),\n",
        "    \"ru_RU\": (\"piper-sample-generator/models/ru_RU-dmitri-medium.onnx\", \"onnx\"),\n",
        "    \"zh_CN\": (\"piper-sample-generator/models/zh_CN-huayan-medium.onnx\", \"onnx\")\n",
        "}\n",
        "\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "\n",
        "for d in [positive_train, positive_test]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "samples_per_lang = 650\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"piper-sample-generator\")\n",
        "from generate_samples import generate_samples\n",
        "\n",
        "def generate_with_piper_binary(text, model_path, output_file):\n",
        "    cmd = f'echo \"{text}\" | /usr/local/bin/piper --model {model_path} --output_file {output_file} 2>/dev/null'\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
        "    return result.returncode == 0\n",
        "\n",
        "def backup_language(lang):\n",
        "    \"\"\"Backup one language to Drive immediately\"\"\"\n",
        "    lang_backup = f\"{backup_base}/{lang}\"\n",
        "    os.makedirs(lang_backup, exist_ok=True)\n",
        "\n",
        "    # Copy this language's files\n",
        "    import glob\n",
        "    train_files = glob.glob(f\"{positive_train}/{lang}_*.wav\")\n",
        "    test_files = glob.glob(f\"{positive_test}/{lang}_*.wav\")\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy(f, f\"{lang_backup}/train_{os.path.basename(f)}\")\n",
        "    for f in test_files:\n",
        "        shutil.copy(f, f\"{lang_backup}/test_{os.path.basename(f)}\")\n",
        "\n",
        "    print(f\"   💾 BACKED UP {len(train_files)+len(test_files)} files to Drive!\")\n",
        "\n",
        "# Check what's already done\n",
        "completed = [d for d in os.listdir(backup_base) if os.path.isdir(f\"{backup_base}/{d}\")]\n",
        "print(f\"Already completed languages: {completed}\")\n",
        "\n",
        "# Generate each language with immediate backup\n",
        "for lang, (model_path, model_type) in languages.items():\n",
        "    if lang in completed:\n",
        "        print(f\"\\n✓ {lang} already backed up, skipping...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🎤 {lang}: Generating {samples_per_lang} samples...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # TRAINING\n",
        "    if model_type == \"pt\":\n",
        "        try:\n",
        "            generate_samples(\n",
        "                text=[\"Hello James\"], model=model_path, max_samples=samples_per_lang,\n",
        "                batch_size=50, noise_scales=[0.98], noise_scale_ws=[0.98],\n",
        "                length_scales=[0.75, 1.0, 1.25], output_dir=positive_train,\n",
        "                auto_reduce_batch_size=True,\n",
        "                file_names=[f\"{lang}_{uuid.uuid4().hex}.wav\" for _ in range(samples_per_lang)]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "            continue\n",
        "    else:\n",
        "        success = 0\n",
        "        for i in range(samples_per_lang):\n",
        "            output = f\"{positive_train}/{lang}_{uuid.uuid4().hex}.wav\"\n",
        "            if generate_with_piper_binary(\"Hello James\", model_path, output):\n",
        "                success += 1\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"   Training: {i+1}/{samples_per_lang} ({success} successful)\")\n",
        "\n",
        "    # VALIDATION\n",
        "    if model_type == \"pt\":\n",
        "        try:\n",
        "            generate_samples(\n",
        "                text=[\"Hello James\"], model=model_path, max_samples=samples_per_lang,\n",
        "                batch_size=50, noise_scales=[0.98], noise_scale_ws=[0.98],\n",
        "                length_scales=[0.75, 1.0, 1.25], output_dir=positive_test,\n",
        "                auto_reduce_batch_size=True,\n",
        "                file_names=[f\"{lang}_{uuid.uuid4().hex}.wav\" for _ in range(samples_per_lang)]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "            continue\n",
        "    else:\n",
        "        success = 0\n",
        "        for i in range(samples_per_lang):\n",
        "            output = f\"{positive_test}/{lang}_{uuid.uuid4().hex}.wav\"\n",
        "            if generate_with_piper_binary(\"Hello James\", model_path, output):\n",
        "                success += 1\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"   Validation: {i+1}/{samples_per_lang}\")\n",
        "\n",
        "    # BACKUP IMMEDIATELY\n",
        "    print(f\"\\n   💾 Backing up {lang} to Drive...\")\n",
        "    backup_language(lang)\n",
        "    print(f\"   ✓ {lang} COMPLETE AND SAVED!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ ALL LANGUAGES COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total samples: {len(os.listdir(positive_train))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESTORE: Copy all backed-up samples from Drive to local directories\n",
        "import os, shutil, glob\n",
        "\n",
        "backup_base = \"/content/drive/MyDrive/hello_james_samples\"\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"📥 RESTORING ALL SAMPLES FROM DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get all backed up languages\n",
        "backed_up_langs = [d for d in os.listdir(backup_base)\n",
        "                   if os.path.isdir(f\"{backup_base}/{d}\")]\n",
        "\n",
        "print(f\"Found backups: {backed_up_langs}\\n\")\n",
        "\n",
        "total_restored = 0\n",
        "for lang in backed_up_langs:\n",
        "    lang_backup = f\"{backup_base}/{lang}\"\n",
        "    files = os.listdir(lang_backup)\n",
        "\n",
        "    print(f\"Restoring {lang}: {len(files)} files...\")\n",
        "\n",
        "    for filename in files:\n",
        "        src = f\"{lang_backup}/{filename}\"\n",
        "\n",
        "        # Determine if train or test\n",
        "        if filename.startswith(\"train_\"):\n",
        "            dest = f\"{positive_train}/{filename[6:]}\"  # Remove \"train_\" prefix\n",
        "        elif filename.startswith(\"test_\"):\n",
        "            dest = f\"{positive_test}/{filename[5:]}\"  # Remove \"test_\" prefix\n",
        "        else:\n",
        "            print(f\"  ⚠️ Unknown file: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Copy if not already there\n",
        "        if not os.path.exists(dest):\n",
        "            shutil.copy(src, dest)\n",
        "            total_restored += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"✓ RESTORED {total_restored} files from Drive!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training samples: {len(os.listdir(positive_train))}\")\n",
        "print(f\"Test samples: {len(os.listdir(positive_test))}\")\n",
        "print(\"\\nReady for augmentation and training!\")"
      ],
      "metadata": {
        "id": "9FC78ya9mKQN"
      },
      "id": "9FC78ya9mKQN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 PRE-TRAINING VALIDATION: Check EVERYTHING before starting\n",
        "import os\n",
        "import wave\n",
        "import glob\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 PRE-TRAINING VALIDATION CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_good = True\n",
        "\n",
        "# 1. Check sample directories and counts\n",
        "print(\"\\n1️⃣ Checking sample directories...\")\n",
        "base_dir = \"./my_custom_model/Hello_James\"\n",
        "positive_train = f\"{base_dir}/positive_train\"\n",
        "positive_test = f\"{base_dir}/positive_test\"\n",
        "negative_train = f\"{base_dir}/negative_train\"\n",
        "negative_test = f\"{base_dir}/negative_test\"\n",
        "\n",
        "train_files = os.listdir(positive_train) if os.path.exists(positive_train) else []\n",
        "test_files = os.listdir(positive_test) if os.path.exists(positive_test) else []\n",
        "\n",
        "print(f\"   Training samples: {len(train_files)}\")\n",
        "print(f\"   Test samples: {len(test_files)}\")\n",
        "\n",
        "expected_per_lang = 650\n",
        "expected_langs = 7\n",
        "expected_total = expected_per_lang * expected_langs\n",
        "\n",
        "if len(train_files) < expected_total * 0.9:  # Allow 10% tolerance\n",
        "    print(f\"   ⚠️ WARNING: Expected ~{expected_total} training samples, got {len(train_files)}\")\n",
        "    all_good = False\n",
        "else:\n",
        "    print(f\"   ✓ Training sample count looks good!\")\n",
        "\n",
        "if len(test_files) < expected_total * 0.9:\n",
        "    print(f\"   ⚠️ WARNING: Expected ~{expected_total} test samples, got {len(test_files)}\")\n",
        "    all_good = False\n",
        "else:\n",
        "    print(f\"   ✓ Test sample count looks good!\")\n",
        "\n",
        "# 2. Check language distribution\n",
        "print(\"\\n2️⃣ Checking language distribution...\")\n",
        "languages = [\"en_US\", \"de_DE\", \"es_ES\", \"fr_FR\", \"pt_BR\", \"ru_RU\", \"zh_CN\"]\n",
        "lang_counts = {}\n",
        "\n",
        "for lang in languages:\n",
        "    train_count = len([f for f in train_files if f.startswith(lang)])\n",
        "    test_count = len([f for f in test_files if f.startswith(lang)])\n",
        "    lang_counts[lang] = (train_count, test_count)\n",
        "\n",
        "    total = train_count + test_count\n",
        "    if total > 0:\n",
        "        print(f\"   {lang}: {train_count} train + {test_count} test = {total} total\")\n",
        "    else:\n",
        "        print(f\"   ❌ {lang}: NO SAMPLES FOUND!\")\n",
        "        all_good = False\n",
        "\n",
        "# 3. Check sample rates\n",
        "print(\"\\n3️⃣ Checking sample rates (should be 16000 Hz)...\")\n",
        "sample_rates = {}\n",
        "for filename in train_files[:5]:  # Check first 5 files\n",
        "    filepath = f\"{positive_train}/{filename}\"\n",
        "    try:\n",
        "        with wave.open(filepath, 'rb') as wav:\n",
        "            rate = wav.getframerate()\n",
        "            sample_rates[rate] = sample_rates.get(rate, 0) + 1\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️ Error reading {filename}: {e}\")\n",
        "        all_good = False\n",
        "\n",
        "if sample_rates:\n",
        "    for rate, count in sample_rates.items():\n",
        "        if rate == 16000:\n",
        "            print(f\"   ✓ Sample rate: {rate} Hz (correct)\")\n",
        "        else:\n",
        "            print(f\"   ❌ Sample rate: {rate} Hz (WRONG! Should be 16000 Hz)\")\n",
        "            print(f\"   → Run FIX 3 (resample) cell before training!\")\n",
        "            all_good = False\n",
        "\n",
        "# 4. Check file sizes (detect empty files)\n",
        "print(\"\\n4️⃣ Checking for empty/corrupted files...\")\n",
        "empty_files = 0\n",
        "small_files = 0\n",
        "for filename in train_files[:100]:  # Sample 100 files\n",
        "    filepath = f\"{positive_train}/{filename}\"\n",
        "    size = os.path.getsize(filepath)\n",
        "    if size == 0:\n",
        "        empty_files += 1\n",
        "    elif size < 1000:  # Less than 1KB is suspicious\n",
        "        small_files += 1\n",
        "\n",
        "if empty_files > 0:\n",
        "    print(f\"   ❌ Found {empty_files} empty files!\")\n",
        "    all_good = False\n",
        "elif small_files > 5:\n",
        "    print(f\"   ⚠️ Found {small_files} suspiciously small files\")\n",
        "else:\n",
        "    print(f\"   ✓ No empty files detected\")\n",
        "\n",
        "# 5. Check background/noise data\n",
        "print(\"\\n5️⃣ Checking background audio datasets...\")\n",
        "required_dirs = {\n",
        "    \"./audioset_16k\": \"AudioSet background noise\",\n",
        "    \"./fma\": \"FMA music dataset\",\n",
        "    \"./mit_rirs\": \"MIT room impulse responses\"\n",
        "}\n",
        "\n",
        "for dir_path, description in required_dirs.items():\n",
        "    if os.path.exists(dir_path):\n",
        "        file_count = len([f for f in os.listdir(dir_path) if f.endswith('.wav')])\n",
        "        print(f\"   ✓ {description}: {file_count} files\")\n",
        "    else:\n",
        "        print(f\"   ❌ {description}: NOT FOUND at {dir_path}\")\n",
        "        all_good = False\n",
        "\n",
        "# 6. Check feature data file (16GB embeddings)\n",
        "print(\"\\n6️⃣ Checking feature embedding file...\")\n",
        "feature_file = \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
        "if os.path.exists(feature_file):\n",
        "    size_gb = os.path.getsize(feature_file) / (1024**3)\n",
        "    print(f\"   ✓ Feature file exists: {size_gb:.1f} GB\")\n",
        "else:\n",
        "    print(f\"   ❌ Feature file NOT FOUND: {feature_file}\")\n",
        "    all_good = False\n",
        "\n",
        "# 7. Check config file\n",
        "print(\"\\n7️⃣ Checking training config...\")\n",
        "if os.path.exists('my_model.yaml'):\n",
        "    import yaml\n",
        "    with open('my_model.yaml', 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "\n",
        "    print(f\"   Target phrase: {config.get('target_phrase', 'NOT SET')}\")\n",
        "    print(f\"   Model name: {config.get('model_name', 'NOT SET')}\")\n",
        "    print(f\"   Training steps: {config.get('steps', 'NOT SET')}\")\n",
        "    print(f\"   n_samples: {config.get('n_samples', 'NOT SET')}\")\n",
        "\n",
        "    if config.get('target_phrase') != ['Hello James']:\n",
        "        print(f\"   ⚠️ Target phrase mismatch!\")\n",
        "        all_good = False\n",
        "    else:\n",
        "        print(f\"   ✓ Config looks good\")\n",
        "else:\n",
        "    print(f\"   ❌ Config file 'my_model.yaml' NOT FOUND!\")\n",
        "    all_good = False\n",
        "\n",
        "# 8. Check Python environment\n",
        "print(\"\\n8️⃣ Checking Python packages...\")\n",
        "try:\n",
        "    import torch\n",
        "    import torchaudio\n",
        "    import openwakeword\n",
        "    print(f\"   ✓ PyTorch: {torch.__version__}\")\n",
        "    print(f\"   ✓ torchaudio: {torchaudio.__version__}\")\n",
        "    print(f\"   ✓ openwakeword: installed\")\n",
        "except ImportError as e:\n",
        "    print(f\"   ❌ Missing package: {e}\")\n",
        "    all_good = False\n",
        "\n",
        "# FINAL VERDICT\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_good:\n",
        "    print(\"✅ ALL CHECKS PASSED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"🚀 READY TO TRAIN!\")\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. Run Step 2: Data augmentation + feature extraction (~15 mins)\")\n",
        "    print(\"2. Run Step 3: Train model (~30-60 mins on A100)\")\n",
        "    print(\"3. Download your .tflite model!\")\n",
        "else:\n",
        "    print(\"❌ VALIDATION FAILED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"⚠️ FIX THE ISSUES ABOVE BEFORE TRAINING!\")\n",
        "    print(\"\\nCommon fixes:\")\n",
        "    print(\"- Run RESTORE cell to get all samples from Drive\")\n",
        "    print(\"- Run FIX 3 (resample) if sample rate is wrong\")\n",
        "    print(\"- Re-run download cells for missing datasets\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "UA-FRbBbmjS3"
      },
      "id": "UA-FRbBbmjS3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX 3 CORRECTED: Resample all clips from 22050 Hz to 16000 Hz\n",
        "import os\n",
        "import scipy.io.wavfile as wavfile\n",
        "import scipy.signal\n",
        "from tqdm import tqdm\n",
        "\n",
        "# CORRECT PATH (lowercase)\n",
        "base_dir = \"./my_custom_model/hello_James\"\n",
        "\n",
        "# First, delete the old features file created with wrong sample rate\n",
        "features_file = f\"{base_dir}/positive_features_train.npy\"\n",
        "if os.path.exists(features_file):\n",
        "    os.remove(features_file)\n",
        "    print(f\"✓ Deleted old features file\\n\")\n",
        "\n",
        "# Resample all audio files\n",
        "for subdir in ['positive_train', 'positive_test', 'negative_train', 'negative_test']:\n",
        "    path = f\"{base_dir}/{subdir}\"\n",
        "    if not os.path.exists(path):\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "    print(f\"Resampling {len(files)} files in {subdir}...\")\n",
        "\n",
        "    for filename in tqdm(files):\n",
        "        filepath = os.path.join(path, filename)\n",
        "        sr, data = wavfile.read(filepath)\n",
        "\n",
        "        if sr != 16000:\n",
        "            # Resample to 16000 Hz\n",
        "            number_of_samples = round(len(data) * 16000 / sr)\n",
        "            resampled = scipy.signal.resample(data, number_of_samples)\n",
        "            wavfile.write(filepath, 16000, resampled.astype(data.dtype))\n",
        "\n",
        "print(\"\\n✓ All clips resampled to 16000 Hz!\")\n",
        "print(\"Now run Step 2 (augmentation cell)!\")"
      ],
      "metadata": {
        "id": "I4lh_UYL7-kx",
        "outputId": "c1c70dcf-5298-46ec-81dd-a85ddddf20e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I4lh_UYL7-kx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Deleted old features file\n",
            "\n",
            "Resampling 1000 files in positive_train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:06<00:00, 151.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling 1000 files in positive_test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 271.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling 1000 files in negative_train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 227.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling 1000 files in negative_test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 177.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ All clips resampled to 16000 Hz!\n",
            "Now run Step 2 (augmentation cell)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afeedae4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:56:08.781018Z",
          "start_time": "2023-09-04T13:55:40.203515Z"
        },
        "id": "afeedae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885305d0-5477-4ec2-e8e5-4961a319c800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-27 01:42:34.136743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764207754.170881   10342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764207754.179746   10342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-11-27 01:42:34.212418: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = PitchShift(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = BandStopFilter(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddColoredNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddBackgroundNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Gain(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Compose(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
            "  warnings.warn(\n",
            "Computing features: 100% 62/62 [00:43<00:00,  1.42it/s]\n",
            "Trimming empty rows: 1it [00:00, 66.03it/s]\n",
            "Computing features: 100% 62/62 [00:42<00:00,  1.47it/s]\n",
            "Trimming empty rows: 1it [00:00, 61.07it/s]\n",
            "Computing features: 100% 62/62 [00:40<00:00,  1.52it/s]\n",
            "Trimming empty rows: 1it [00:00, 64.55it/s]\n",
            "Computing features:  74% 46/62 [00:30<00:09,  1.68it/s]"
          ]
        }
      ],
      "source": [
        "# Step 2: Augment the generated clips\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad81ea0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:11:14.742260Z",
          "start_time": "2023-09-04T15:07:03.755159Z"
        },
        "id": "9ad81ea0"
      },
      "outputs": [],
      "source": [
        "# Step 3: Train model\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSKWWLalnYzR",
      "metadata": {
        "id": "JSKWWLalnYzR"
      },
      "outputs": [],
      "source": [
        "# Step 4 (Optional): On Google Colab, sometimes the .tflite model isn't saved correctly\n",
        "# If so, run this cell to retry\n",
        "\n",
        "# Manually save to tflite as this doesn't work right in colab\n",
        "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "    # imports\n",
        "    import onnx\n",
        "    import logging\n",
        "    import tempfile\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Convert to tflite from onnx model\n",
        "    onnx_model = onnx.load(onnx_model_path)\n",
        "    tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "    return None\n",
        "\n",
        "convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9OyUW3ltOSs",
      "metadata": {
        "id": "f9OyUW3ltOSs"
      },
      "source": [
        "After the model finishes training, the auto training script will automatically convert it to ONNX and tflite versions, saving them as `my_custom_model/<model_name>.onnx/tflite` in the present working directory, where `<model_name>` is defined in the YAML training config file. Either version can be used as normal with `openwakeword`. I recommend testing them with the [`detect_from_microphone.py`](https://github.com/dscripka/openWakeWord/blob/main/examples/detect_from_microphone.py) example script to see how the model performs!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3de46a27878e4911ae5ae0c03b7e66a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fc98fbb222e4f1b84093527c9d8eef5",
              "IPY_MODEL_a910af17255b42a4bb0f4511aa00cff4",
              "IPY_MODEL_855f2a7c57c2423e94939390dfdd981d"
            ],
            "layout": "IPY_MODEL_abcfddc9de4a40739ee4ea8e8918692a"
          }
        },
        "5fc98fbb222e4f1b84093527c9d8eef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0d7910b28c4fd99087dfe540be6ac3",
            "placeholder": "​",
            "style": "IPY_MODEL_7b9af137ebba4ba4bfcaf76f7cfd46e4",
            "value": "Downloading readme: 100%"
          }
        },
        "a910af17255b42a4bb0f4511aa00cff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944cf785ae5b40e2ad567079ff5d1de8",
            "max": 936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edef5e08fb1646f38b46504ed658e9fd",
            "value": 936
          }
        },
        "855f2a7c57c2423e94939390dfdd981d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ee0698619b42bc8e3b323ec478828f",
            "placeholder": "​",
            "style": "IPY_MODEL_aef9cf123a8742cc95efd4f216622d23",
            "value": " 936/936 [00:00&lt;00:00, 104kB/s]"
          }
        },
        "abcfddc9de4a40739ee4ea8e8918692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0d7910b28c4fd99087dfe540be6ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9af137ebba4ba4bfcaf76f7cfd46e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944cf785ae5b40e2ad567079ff5d1de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edef5e08fb1646f38b46504ed658e9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06ee0698619b42bc8e3b323ec478828f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef9cf123a8742cc95efd4f216622d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3730a67c44654f468fa3b0e1337f2847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88dbb40ad3174d9190f9da40d2d7f806",
              "IPY_MODEL_619c8a7514a84ade9adc17bd96497af1",
              "IPY_MODEL_f744748204fd4807b4e50709651051ed"
            ],
            "layout": "IPY_MODEL_8a0febc97315407dac6fe5be8bbf79c1"
          }
        },
        "88dbb40ad3174d9190f9da40d2d7f806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7d3de401c342be86277311437ae623",
            "placeholder": "​",
            "style": "IPY_MODEL_fba5469d2d8b427d9cd5fc7f8289d57e",
            "value": "Resolving data files: 100%"
          }
        },
        "619c8a7514a84ade9adc17bd96497af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550093ec0aa744d98a59da0f146871f0",
            "max": 270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00a948b7213a4e53b38ce71b13201df7",
            "value": 270
          }
        },
        "f744748204fd4807b4e50709651051ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a914be22ca614f978be37e05f2223d08",
            "placeholder": "​",
            "style": "IPY_MODEL_948d416c389846ecbd3f746cdc06913f",
            "value": " 270/270 [00:00&lt;00:00, 72.15it/s]"
          }
        },
        "8a0febc97315407dac6fe5be8bbf79c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc7d3de401c342be86277311437ae623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba5469d2d8b427d9cd5fc7f8289d57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "550093ec0aa744d98a59da0f146871f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a948b7213a4e53b38ce71b13201df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a914be22ca614f978be37e05f2223d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948d416c389846ecbd3f746cdc06913f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec8d55bd7c834e49b5d78c43fb8c78e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9035847498794337bfd4ffcdfe0cb9e5",
              "IPY_MODEL_c8c0d4f7942c428ba484e58573869aed",
              "IPY_MODEL_c3103c02273a4b409add5c641c8f6b1d"
            ],
            "layout": "IPY_MODEL_8360062307224683ab988bd3f5e28a5a"
          }
        },
        "9035847498794337bfd4ffcdfe0cb9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0409fec5029400892c95aff59f05f3e",
            "placeholder": "​",
            "style": "IPY_MODEL_892dbd13b15c4a1781c7fd2b11325dc1",
            "value": "Downloading builder script: "
          }
        },
        "c8c0d4f7942c428ba484e58573869aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b1b7c51c7a4326ab3101578bacd8d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050102253a714efcac91be62af4908ef",
            "value": 1
          }
        },
        "c3103c02273a4b409add5c641c8f6b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4353db2b1ec420891c06eb931bfc0d3",
            "placeholder": "​",
            "style": "IPY_MODEL_864236d857fd4c20b847b6fe2bba91fd",
            "value": " 46.3k/? [00:00&lt;00:00, 4.87MB/s]"
          }
        },
        "8360062307224683ab988bd3f5e28a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0409fec5029400892c95aff59f05f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892dbd13b15c4a1781c7fd2b11325dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0b1b7c51c7a4326ab3101578bacd8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "050102253a714efcac91be62af4908ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4353db2b1ec420891c06eb931bfc0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864236d857fd4c20b847b6fe2bba91fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86ee7c07a992446da4bd247bf989518d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ddb49d4f17d4906a2b83a7f486afc0f",
              "IPY_MODEL_9b9fa893cefc49a197a9e76383bc02d7",
              "IPY_MODEL_183f52ec7357466b98e4d8b984af5eb8"
            ],
            "layout": "IPY_MODEL_10a20fc4bf1243d7ac9530e6dae38943"
          }
        },
        "0ddb49d4f17d4906a2b83a7f486afc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_716f6b42e99d48dab530ec7cea18a211",
            "placeholder": "​",
            "style": "IPY_MODEL_fc93db92ccca4c95b483eb76dde4f2ea",
            "value": "Downloading readme: 100%"
          }
        },
        "9b9fa893cefc49a197a9e76383bc02d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a93fe5693d1847e88d4607d768f2d72e",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b95806227f34bbcb5a4d30efa19f0d5",
            "value": 25
          }
        },
        "183f52ec7357466b98e4d8b984af5eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24dde86654c24740964fa1c98afcc750",
            "placeholder": "​",
            "style": "IPY_MODEL_a253ac338dae479fa1c040c78d55f871",
            "value": " 25.0/25.0 [00:00&lt;00:00, 3.19kB/s]"
          }
        },
        "10a20fc4bf1243d7ac9530e6dae38943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716f6b42e99d48dab530ec7cea18a211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc93db92ccca4c95b483eb76dde4f2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a93fe5693d1847e88d4607d768f2d72e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b95806227f34bbcb5a4d30efa19f0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24dde86654c24740964fa1c98afcc750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a253ac338dae479fa1c040c78d55f871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}